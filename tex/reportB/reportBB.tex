\documentclass[a4paper]{jfp}
\usepackage[margin=2cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{url}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\usepackage[svgnames]{xcolor}
\ifpdf
  \usepackage{pdfcolmk}
\fi
\usepackage{graphicx}
\usepackage{hyperref}
%\usepackage[outline]{contour}
\usepackage{tikz}
\usepackage{pifont}   
\usepackage{mathabx}
\usepackage{float}
\floatstyle{boxed} 
\restylefloat{figure}
%\usepackage[square,super, comma]{natbib}
\newlength{\tpheight}\setlength{\tpheight}{0.9\textheight}
\newlength{\txtheight}\setlength{\txtheight}{0.9\tpheight}
\newlength{\tpwidth}\setlength{\tpwidth}{0.9\textwidth}
\newlength{\txtwidth}\setlength{\txtwidth}{0.9\tpwidth}
\newlength{\drop}                     
\synctex=1
\newcommand{\outsidein}{\textsc{OutsideIn}(X)}
\setlength{\parindent}{0cm}

\newcommand*{\titleGP}{\begingroup% Geometric Modeling

\drop=0.1\txtheight
\centering
\vspace*{\baselineskip}
\rule{\txtwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt}
\rule{\txtwidth}{0.4pt}\\[\baselineskip]
{\LARGE FORMALISING\\ GHC'S TYPE \\[0.3\baselineskip] SYSTEM}\\[0.2\baselineskip]
\rule{\txtwidth}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt}
\rule{\txtwidth}{1.6pt}\\[\baselineskip]
\scshape
A Rigorous and Machine Checked Formulation of $\textsc{OutsideIn}(X)$ \\
in a Dependently Typed Proof Assistant \\
\par
\vspace*{2\baselineskip}
A Thesis By \\[\baselineskip]
{\Large LIAM O'CONNOR-DAVIS}
 \\[\baselineskip]
Supervised By \\[\baselineskip]
{\Large MANUEL M. T. CHAKRAVARTY}
 \\[\baselineskip]
{\itshape School of Computer Science and Engineering \\ University of New South Wales \par}
\vfill
\includegraphics[width=4cm]{unswcrest.pdf} \\

\medskip

%\plogo\\
{\scshape May 20th 2012} \\
\par
\endgroup}   
%\linespread{1.5}
%\sectionstyle{dash}\renewcommand*{\chaptitlefont}{\normalfont\itshape\LARGE}
%\setlength{\beforechapskip}{2\onelineskip}
%\setsecheadstyle{\normalfont\Large\raggedright}



\begin{document}
\setlength{\parskip}{9pt plus 1pt minus 1pt}
%	\begin{titlepage}
%\frontmatter
\pagestyle{empty}
\titleGP
\clearpage
\pagestyle{plain}
%\mainmatter
\begin{abstract}

GHC, a Haskell compiler \cite{Anonymous:2010we}, offers numerous extensions to the standard Haskell type system \cite{Schrijvers:2009jg,
   Yorgey:2012:GHP:2103786.2103795, citeulike:9320233, Jones:2007dr}.  Each of these extensions is usually specified only semi-formally, and only in
isolation. Very little work has been done examining type system properties when multiple type system extensions are combined, which is the scenario
actually being faced by GHC developers. To address this, the GHC team published $\outsidein$, a mostly-rigorous formulation of GHC's type inference
system \cite{Vytiniotis:2011:OMT:2139531.2139533}, which encompasses every type system extension developed for GHC to date. 

We formalise $\outsidein$ in a mechanical proof assistant, in order to provide a body of formal work upon which future extensions can be developed. By
using a mechanical proof assistant we not only ensure correctness of our proofs and complete rigor in our definitions, but also make possible the
incremental development of the formal work alongside the more practically-minded type checker implementation in GHC\@. This additional accessibility
will hopefully prevent further extensions from being developed without regard to the effect such an extension may have on other parts of the type
system.

Our formalisation is developed in Agda \cite{conf/afp/norell08}. As a dependently typed programming language which enforces totality, Agda doubles as
a proof assistant \cite{Howard:1980vs}. It is still under heavy development, and is quite experimental. By formalising $\outsidein$ in Agda, we
demonstrate its readiness for type system work, and also provide an example to encourage further type systems research in Agda.

\end{abstract}

\tableofcontents
%\end{titlepage}
\newpage

\section{Introduction}

Haskell is a purely functional programming language, with a type system that supports algebraic data types, type inference, parametric (higher-kinded)
polymorphism, and type class constraints \cite{Anonymous:2010we}. In recent years, the developers of GHC, a prominent Haskell compiler, have
implemented a variety of extensions to this type system, with the aim of providing greater expressiveness, ease of use, or static verification
capabilities. Some are straightforward, such as generalising type classes to type relations via multi-parameter type classes. Some require more
significant extensions to the type system, such as type families \cite{citeulike:9320233} and the earlier functional dependencies extension; some make
type inference significantly more difficult and are major extensions, such as GADTs \cite{Schrijvers:2009jg}, impredicative polymorphism and
arbitrary-rank types \cite{Jones:2007dr}.

While GHC accommodates all of these extensions simultaneously, the papers that introduce each one discuss type inference and type checking only in
isolation, and sometimes quite informally. This makes the properties of GHC's type reconstruction algorithm difficult to determine when multiple
extensions are combined.  

As a first step towards solving this problem, the GHC team (specifically Vytiniotis, Peyton Jones, Schrijvers and Suzmann) published $\outsidein$, a
modular type inference system that accommodates all of these extensions (and possibly more), along with soundness and principality proofs
\cite{Vytiniotis:2011:OMT:2139531.2139533}. 

Our work is intended to more rigorously formalise $\outsidein$ in the dependently-typed programming language \emph{cum} proof assistant Agda 2
\cite{conf/afp/norell08}.

\subsection{Why mechanise $\outsidein$?}

Any handwritten formalisation or proof, much like a handwritten algorithm, will likely lack the amount of rigor necessary to be accepted by a proof
assistant. Formalising $\outsidein$ \emph{in a proof assistant} is therefore more difficult than it appears at first glance. The use of a proof
assistant requires us to redesign those parts of the system that are not amenable to automated checking, and to make rigorous all those
parts of the original formalisation that are left to the reader's intuition.

By formalising $\outsidein$ in a proof assistant, we achieve two main goals. Firstly, we make explicit that which was implicit, and to prove that
which was assumed in the original $\outsidein$ paper, ensuring that our formal work stands on solid ground; and secondly, we encourage those
developing extensions for the type system to use our work as a foundation for their formalisation, along with the necessary practical implementation
of the new extension in GHC's type checker. By making proofs available as code, we hope to mitigate the social problem of formal work on a type system
being published in a long paper and subsequently ignored\footnote{See the new {\tt DataKinds} extension \cite{Yorgey:2012:GHP:2103786.2103795} }. 

\subsection{Why Agda?}

Agda is an interesting choice of proof assistant for this task. This choice was made not simply because Agda is the most familiar to the author, but
also because Agda is still quite experimental, and the subject of a great deal of new research. By formalising $\outsidein$ in Agda, we show
Agda's readiness for type systems work, and provide an example for others researching type systems and considering Agda. Similar work has been done
for $HM(X)$ in proof assistants such as Coq \cite{Dubois00provingml} and Isabelle \cite{Naraschewski:1999:TIV:594135.594270}, whereas our
formalisation of $\outsidein$ is the first such work performed in Agda. 

\subsection{A Brief Introduction to Agda}
 
Agda is a programming language with a concrete syntax similar to Haskell, based on the dependent intuitionistic type theory of Per Martin-L\"of
\cite{MartinLof:1984tr}. Agda enforces totality by mandating that all functions be structurally recursive\footnote{Or, in the case of coinduction,
structurally corecursive.}, meaning that programs correspond to proofs in a higher order intuitionistic logic. Features include (co)-inductive data
types and families, ``mix-fix'' syntax \cite{springerlink:10.1007/978-3-642-24452-0_5}, parameterised modules, ``View from the left'' style pattern
matching \cite{McBride:2004:VL:967492.967496} and compile time proof irrelevance annotations. For a complete tutorial in Agda programming, we defer to
the experts \cite{conf/afp/norell08}; the Agda examples in this thesis only require a rudimentary knowledge of Agda's syntax.

\subsubsection{A Key Point of Difference}

Unlike other dependently typed theorem provers such as Coq, when working in Agda one does not write a proof script consisting of a series of proof
\emph{tactics} which transform or generate a proof \emph{object} (i.e.\ the dependently typed program); the program or proof is written directly. This
has two main implications:

\begin{enumerate}
   \item \emph{Proof terms are explicit, automation is not available}. There is limited opportunity for automated generation and manipulation of the
      proof object (i.e.\ complicated proof tactics) when one writes the proof object code directly. Recently, a new reflection interface was added in
      Agda version 2.3.0, which allows Agda programs to inspect the current goal and generate solutions for it. It offers a kind of automatic
      generation of proof objects using Agda itself as a tactic language, however it remains highly experimental and few tactics are available. Our
      formalisation does not make use of this feature.

   \item \emph{Great care must be taken to keep representations manageable}. In most theorem provers, the formal properties we want to prove and the
      definitions they describe tend to be quite distinct. Because Agda uses the same language to talk about both, we can combine them in ways that
      would be impossible in Isabelle/HOL or unusual in Coq\footnote{Such tricks are certainly possible in Coq, but less commonly employed.}. Key
      properties about our definitions are implied by their structure, rather than independently proven as lemmas, using a variety of definitional
      tricks. We employ these tricks extensively for our representation of names, substitutions, and abstract syntax trees. 

\end{enumerate}

\subsection{Overview}

Our approach to $\outsidein$ is discussed in chapter two, where we rework various parts of $\outsidein$ that were informally presented originally,
providing a more rigorous formalisation. Our method of term representation, including our use of an \emph{indexed abstract syntax tree} is explained
in chapter three.  This choice of representation is very important for Agda formalisations, as mentioned in the previous section. Chapter four
outlines our representation of the $\outsidein$ system itself, and chapter five discusses our simple instantiation of the \emph{X} parameter to
sanity-check our definitions. Lastly, chapter six discusses future directions for this work, including proof work and instantiating the system for
Haskell itself.

\newpage

\section{Making $\outsidein$ Rigorous}

$\outsidein$, published in \cite{Vytiniotis:2011:OMT:2139531.2139533}, is an approach to type inference approach that supports modular type inference
and, most interestingly, \emph{local assumptions}, such as those introduced by pattern matching on a \emph{generalisd algebraic data type}, or GADT\@.
A GADT is more general than a regular algebraic data type because its constructors can have substantially more flexible types, including constraints
and type variables not mentioned in the constructed type. This allows for a variety of useful features, such as existential quantification and type
indexing \cite{Schrijvers:2009jg}.

For example, suppose we had the following GADT.

\begin{displaymath}
	\begin{array}{ll}		
		\textbf{data} & \mathit{EqOrShow}\ :: \mathtt{*} \rightarrow \mathtt{*}\ \textbf{where} \\
		              & \begin{array}{lcl}
                         \text{IsEq} & :: & (\mathit{Eq}\ \tau) \Rightarrow \mathit{EqOrShow}\ \tau \\
                         \text{IsShow} & :: & (\mathit{Show}\ \tau) \Rightarrow \mathit{EqOrShow}\ \tau \\
					    \end{array} \\						
     \end{array}
\end{displaymath}

\medskip

When we pattern match on a GADT such as this, we introduce a \emph{local assumption}, in this case about the type variable $\alpha$:

\begin{displaymath}
\begin{array}{ll}
\mathit{f} :: \mathit{EqOrShow}\ \alpha \rightarrow \alpha \rightarrow \mathit{Either}\ \mathit{String}\ \mathit{Bool} \\
\mathit{f}\ \text{IsEq}\  x = \text{Right}\ (x \equiv x) \\ 
\mathit{f}\  \text{IsShow}\  x = \text{Left}\ (\mathit{show}\ x)\\
\end{array}
\end{displaymath}

\medskip

In this case, the local assumption $\mathit{Eq}\ \alpha$ allows the first alternative to type check, while the local assumption $\mathit{Show}\
\alpha$ allows the second alternative to type check. It is important to note that these assumptions must \emph{remain local}. This is especially
apparent when the constraints are contradictory, for example using equality constraints\footnote{More conventionally, these constructors would not use
   type variables at all, instead each constructor would be parameterised by the concrete types \emph{Int} and \emph{Bool} respectively, however this
   is desugared into a type variable with an explicit equality constraint \cite{Schrijvers:2009jg}}:

\begin{displaymath}
	\begin{array}{ll}		
		\textbf{data} & \mathit{IntOrBool}\ :: \mathtt{*} \rightarrow \mathtt{*}\ \textbf{where} \\
		              & \begin{array}{lcl}
                         \text{IsInt} & :: & (\tau \sim \mathit{Int}) \Rightarrow \mathit{IntOrBool}\ \tau \\
                         \text{IsBool} & :: & (\tau \sim \mathit{Bool}) \Rightarrow \mathit{IntOrBool}\ \tau \\
					    \end{array} \\						
     \end{array}
\end{displaymath}


\medskip

A function which pattern matches on this GADT must obviously localise each constraint assumption to each alternative --- it is impossible for $\alpha
\sim \mathit{Bool}$ and $\alpha \sim \mathit{Int}$ unless $\mathit{Int} \sim \mathit{Bool}$, which is of course not the case\footnote{At least, it is
   not the case in languages outside those whose names contain the letter C and not much else.}. 


\medskip

These local assumptions have historically been difficult to deal with, resulting in lack of principal types. While the general typing rules in a
language may allow terms which lack principal types, $\outsidein$ only infers principal types. If a term lacks a principal type, then type inference
will fail --- it is not complete. Most similar systems, for example $\textsc{HM}(X)$, are complete but lack support for GADTs and type classes
\cite{Pottier:2005ue}.


\subsection{Regarding {\tt let}-generalisation}

When it was first published, $\outsidein$ was not the inference system used by GHC\@. Some significant changes had to be made to the static semantics
of GHC Haskell in order to accommodate it; specifically, generalisation of inferred types in local {\tt let}-expressions was removed. 

Continuing from our earlier example, if we had the following definition:

\nopagebreak

\begin{displaymath}
\begin{array}{ll}
\mathit{f} :: \mathit{IntOrBool}\ \alpha \rightarrow \alpha \rightarrow \mathit{Bool} \\
\mathit{f}\ x\ y = \textbf{let}\ g\ z\ = \mathit{not}\ y\ \textbf{in}  \\
\quad\quad\quad\quad\quad\textbf{case}\ x\ \textbf{of} \\
\quad\quad\quad\quad\quad\quad\begin{array}{lll}
   \mathit{IsInt} & \rightarrow & \text{True} \\
   \mathit{IsBool} & \rightarrow & g\ ()\\
   \end{array}
\end{array}
\end{displaymath}

Most programmers would expect the binding $g$ to give a type error, as it requires $y$ to be of type $\mathit{Bool}$, \emph{before} that has been 
established via pattern matching on $x$\footnote{Note that 
   $\mathit{not} :: \mathit{Bool} \rightarrow \mathit{Bool}$}. 
A principal type does exist, however, for $g$: 
\begin{displaymath}
   g :: \forall \beta. (\alpha \sim \mathit{Bool}) \Rightarrow \beta \rightarrow \mathit{Bool}
\end{displaymath}

That is, the constraint $\alpha \sim \mathit{Bool}$, rather than being rejected, is \emph{abstracted over} in the inferred type. Then, at any call site,
we must provide evidence that $\alpha \sim \mathit{Bool}$, which can be done in this example thanks to the pattern matching. 

The authors of $\outsidein$ state that abstracting over all inferred constraints imposes a significant complexity cost on the implementation of the
type checker, for two main reasons. Firstly, at each call site of such a generalised expression, the (potentially large) set of constraints that have
been abstracted over must be shown satisfiable, which, if necessary for every locally bound expression, would be difficult to perform efficiently.

Secondly, it becomes impossible to solve constraints ``on-the-fly'' in a similar manner to Milner's $\mathcal{W}$ algorithm \cite{Milner78atheory};
instead the compiler must generate all constraints and then solve them in discrete phases. GHC relies on this on-the-fly solving to resolve equality
constraints efficiently using mutable type variables \cite{Jones:2007dr}. They also observe that the principal types inferred by such a method are
often highly confusing and result in the type checker accepting almost-certainly erroneous code, such as the above example. 

In $\outsidein$, this generalisation and abstraction of inferred constraints is only performed \emph{at the top level}, i.e.\ where the type
environment is empty. Therefore, the difficulties above disappear. At the local level, \emph{no generalisation is performed at all}. That is, an
(unannotated) {\tt let}-binding $\mathbf{let}\ x = y\ \mathbf{in}\ e$ is equivalent to $(\lambda x.\ e)\ y$. While a cherished
feature of most type inference algorithms since the original $\mathcal{W}$, {\tt let} generalisation at a local level turns out to be relied upon very
rarely in practice, with a total of only 127 lines needing to be modified in the {\tt base} haskell library consisting of 94,954 lines after this
change was made \cite{Vytiniotis:2010ja}. 


\subsection{Phases of Inference}

As mentioned in the previous section, GHC resolves equality constraints as soon as they can be solved for efficiency reasons.
Specifically, only those constraints which rely on information not available when they are generated are deferred until after constraint generation
for solving. All other constraints are solved immediately.  $\outsidein$, however, presents inference as two separate phases:

\begin{enumerate}
\item \emph{Generate} constraints (according to a set of syntax-directed rules), combining them into one large overall constraint.
\item \emph{Solve} the constraint, using unification and standard constraint-solving methods.	
\end{enumerate} 

The method used by GHC then can be viewed then as interleaving these two phases, whereas $\outsidein$ (at least in theory) keeps them distinct. Our
formal work is derived from $\outsidein$, not GHC, and for such formal work we do not particularly care about the \emph{efficiency} of type inference,
but rather the various properties we can prove about it. For this reason our formalisation also separates these phases. Indeed, we add
\emph{additional} phases to this process, in order to more clearly separate the solver phase, as well as to deal with our extended constraint
language, discussed in the next section. 

\begin{figure}
	\caption{Our updated syntax, slightly extended from $\outsidein$}
   	\begin{displaymath}
	\begin{array}{llcl}
		\text{Term variables} & & \in & x, y, z, f, g, h \\
		\text{Type variables} & & \in & a, b, c \\
		\text{Unification type variables} & & \in & \alpha, \beta, \gamma, \delta \\
		\text{Data constructors} & & \in & K \\
		\text{Type constructors} & & \in & {\tt T} \\
		& \upsilon & ::= & K\ |\ x \\
		\text{Expressions} & e & ::=  & \upsilon\ |\ \lambda x.\ e\ |\ e_1\ e_2\ \\
		                   &   & | & \mathtt{case}\ e\ \mathtt{of}\ \{\overline{K\ \bar{x} \rightarrow e} \} \\
		                   &   & | & \mathtt{let}\ x = e_1\ \mathtt{in}\ e_2\ |\ \mathtt{let}\ x\ \mathtt{::}\ \sigma = e_1\ \mathtt{in}\ e_2\\
		\text{Type schemes} & \sigma & ::= & \forall \bar{a}.\ Q \Rightarrow \tau \\
      \text{Programs} & \mathit{prog} & ::= & f :: \sigma = e, \mathit{prog}\ |\ f = e, \mathit{prog}\ |\ \epsilon \\                     
		\text{Constraints}^* & Q & ::= & \epsilon\ |\ Q_1 \land Q_2\ |\ \tau_1 \sim \tau_2\ |\ \cdots  \\
		\text{Extended constraints} & C & ::= & Q\ |\ C_1 \land' C_2\ |\ \exists \bar{\beta}.\ Q \supset C\ |\ \Finv \alpha.\ C \\
		\text{Monotypes}^* & \tau & ::= & tv\ |\ \mathtt{T}\ \bar{\tau}\ |\ \tau_1 \rightarrow \tau_2\ |\ \cdots \\
		 & tv & ::= & a \\
		\text{Environments} & \Gamma & ::= & \epsilon\ |\ (\upsilon : \sigma), \Gamma \\
		\text{Axiom Schema}^* & \mathcal{Q} & ::= & \cdots \\
	\end{array}	
	\end{displaymath}
	\begin{math}
		\begin{array}{ll}
		\Gamma_0: &  \text{Types of data constructors}^* \\
		& K : \forall\bar{a}\bar{b}.\ Q \Rightarrow \bar{\tau} \rightarrow \mathtt{T}\ \bar{a}
		\end{array}
		\end{math}
   $*$ \text{--- part of the parameter $X$}
   \label{fig:constraints}
\end{figure}

\subsection{The Extended Constraint Language}

Constraint generation in $\outsidein$ is specified independently of the exact constraint system or type system used --- the constraint and type terms
are part of the $X$ parameter. Clearly, some intuitive conditions must be met by these components, summarised in two additional parameters: an
\emph{entailment relation} of global constraint schema to locally inferred constraints, and certain \emph{simplifier conditions} that ensure that the
provided solver behaves consistently with this entailment relation. Specifically, the constraint system must include constraint conjunction and
equality constraints (see fig.~\ref{fig:constraints}) that behave as one would expect, and any locally inferred constraints must be resolved trivially
if they restate an axiom in a global constraint scheme (see fig.~\ref{fig:entailment}). This parameterisation of the system is similar to
$\textsc{HM}(X)$, the parameterised extension of ML's type inference presented in \cite{Odersky97typeinference}\footnote{or the more rigorous
   formalisation presented by Pottier and Remy in their chapter of \emph{Advanced Types and Programming Languages} \cite{Pottier:2005ue}}, with the
addition of global \emph{axiom schema}, which are designed to accommodate Haskell's type classes. Specifically, type class instances can generate
top-level implication constraints such as $\mathit{Show}\ \alpha \Rightarrow \mathit{Show}\ [\alpha]$. In $\outsidein$, these top-level constraints
are expressed in axiom schema and do not form part of the main constraint language. 

In order to deal with local assumptions, $\outsidein$ extends $Q$, the original constraint language in $X$, to an \emph{algorithmic} constraint
language $C$.  $C$ is just $Q$ with an additional form, $\exists\bar{\beta}.\ (Q \supset C)$, where $Q$ is a local assumption, $C$ is a constraint,
and $\bar{\beta}$ are the \emph{only} variables that can be unified while solving the constraint $Q \supset C$. This local assumption is defined as a
constraint in the \emph{original} constraint language $Q$ specifically, rather than the larger $C$, as all local assumptions come from the constraint
clause of a generalised type signature, either provided by the user or in the type of a generalised data constructor; they are not generated locally
by the algorithm itself.

Our presentation of this extended language differs from the presentation in $\outsidein$ in several respects. One minor change is that we make the
separation between the languages $C$, $Q$ and $\mathcal{Q}$ much more clear. In particular, we add a new form of conjunction to the extended language
$C$, written $\phi \land' \psi$, as the conjunction inherited from $Q$ can, technically, only contain $Q$-constraints. In addition, we have changed
$\mathcal{Q}$, the language of axiom schema, so that it no longer includes all of $Q$. Instead, we make no assumptions about the forms that
$\mathcal{Q}$ schema may take, and have reformulated the entailment relation to require \emph{both} a $\mathcal{Q}$-constraint \emph{and} a
$Q$-constraint as context (see fig.~\ref{fig:entailment}). We have also added to the entailment relation requirements for conjunction elimination
rules as well as a rule to deal with $\epsilon$-constraints. These rules were inexplicably absent from the original presentation, despite being
implicitly used repeatedly in the soundness proof presented in the same work.

The constraint solver is also part of the parameter $X$ and therefore can only act on constraints in $Q$, not the extended constraint language $C$.
Therefore, $\outsidein$ includes additional machinery to solve implication constraints given a solver for $Q$-constraints. In $\outsidein$, and in
this thesis, the term \emph{simplifier} is used to describe the $Q$-solver, whereas the term \emph{solver} is reserved for the top-level
\emph{C}-solver.

\newcommand{\nvdasharrow}[0]{\nvdash\!\!\!\!\blacktriangleright\ }
\newcommand{\vdasharrow}[0]{\vdash\!\!\!\!\blacktriangleright\ }

\begin{figure}
	\caption{Entailment relation and simplifier conditions}
   \begin{displaymath}
		\text{\framebox{$ \mathcal{Q};Q \Vdash Q $}} 
   \end{displaymath}
     part of the parameter $X$, subject to the following requirements:
   	\begin{displaymath}
         \begin{array}{llr}
            \text{Tautology} &    \mathcal{Q};Q \Vdash \epsilon & (\textsc{R}_1) \\
            \text{Reflexivity} &  \mathcal{Q};Q \Vdash Q & (\textsc{R}_2) \\
            \text{Transitivity} & \mathcal{Q};Q_1 \Vdash Q_2\ \text{and}\ \mathcal{Q};Q_2 \Vdash Q_3\ 
                                                              \text{implies}\ \mathcal{Q};Q_1 \Vdash Q_3  & (\textsc{R}_3) \\
            \text{Substitution}   & \mathcal{Q};Q_1 \Vdash Q_2\ \text{implies}\ \theta\mathcal{Q};\theta Q_1 \Vdash \theta Q_2\ \text{where $\theta$ 
               is a type substitution} & (\textsc{R}_4) \\
            \text{Conjunction intro.} & \mathcal{Q};Q \Vdash Q_1\ \text{and}\ \mathcal{Q};Q \Vdash Q_2\ 
                                                                  \text{implies}\ \mathcal{Q};Q \Vdash Q_1 \land Q_2 & (\textsc{R}_5)\\
            \text{Conjunction elim.}   & \mathcal{Q};Q_1 \land Q_2 \Vdash Q_1 & (\textsc{R}_6)              \\
                                       & \mathcal{Q};Q_1 \land Q_2 \Vdash Q_2 & (\textsc{R}_7)             \\
            \text{Type eq.\ reflexivity} & \mathcal{Q};Q \Vdash \tau \sim \tau & (\textsc{R}_8) \\
            \text{Type eq.\ symmetry}    & \mathcal{Q};Q \Vdash \tau_1 \sim \tau_2\ \text{implies}\ \mathcal{Q};Q \Vdash \tau_2 \sim \tau_1 
                                         & (\textsc{R}_9) \\
            \text{Type eq.\ transitivity} &  \mathcal{Q};Q \Vdash \tau_1 \sim \tau_2\ \text{and}\ \mathcal{Q};Q \Vdash \tau_2 \sim \tau_3\
            \text{implies}\ \mathcal{Q};Q \Vdash \tau_1 \sim \tau_3 & (\textsc{R}_{10}) \\
            \text{Type eq.\ substitutivity} & \mathcal{Q};Q \Vdash \tau_1 \sim \tau_2\ \text{implies}\ \mathcal{Q};Q \Vdash [\alpha \mapsto \tau_1]
            \tau \sim [\alpha \mapsto \tau_2] \tau & (\textsc{R}_{11})\\
         \end{array}
	\end{displaymath}
   \begin{displaymath}
		\text{\framebox{$ \mathcal{Q};Q_{\text{given}}; \overline{\alpha_\text{tch}} \stackrel{\text{simp}}{\vdasharrow} Q_{\text{wanted}} \leadsto Q_{\text{residual}};\theta  $}} 
   \end{displaymath}
     part of the parameter $X$, subject to the following requirements:

   \begin{tabular}{ll}
   \textbf{Touchable-aware}: & $\mathit{dom}(\theta) \subseteq \overline{\alpha_\text{tch}}$ \\
   \textbf{Soundness}: &  $\mathcal{Q};Q_g \stackrel{\text{simp}}{\vdasharrow} Q_w \leadsto Q_r;\theta  $
   implies
                        $\mathcal{Q} ; Q_g \land Q_r \Vdash \theta Q_w $ \\
   \textbf{Principality}: (Guess-freedom) & $\mathcal{Q};Q_g \stackrel{\text{simp}}{\vdasharrow} Q_w \leadsto Q_r;\theta  $ implies $\mathcal{Q}; Q_g
   \land Q_w \Vdash Q_r \land \mathcal{E}_\theta$ \\ &  where $\mathcal{E}_\theta = \{ (\alpha \sim \tau)\ |\ [\alpha \mapsto \tau] \in \theta \}$.
   \end{tabular}
   \label{fig:entailment}
\end{figure}

\subsection{Fresh Variables}

A common sin against mathematical rigor often committed in type inference literature is that of the magically fresh variable. This is an example taken
from a constraint generation rule (for lambda abstractions) in $\outsidein$:


\begin{displaymath}
\inferrule{\alpha\ \textbf{fresh} \\ \Gamma,(x : \alpha) \vdasharrow e : \tau \leadsto C}
          {\Gamma \vdasharrow \lambda x.\ e : (\alpha \rightarrow \tau) \leadsto C}
\end{displaymath}

\medskip

These fresh variables must be globally unique and in scope throughout the entire program, despite being summoned \emph{ad-hoc} as constraints are
generated; they must be completely unused variable names before being introduced here. Narachewski and Nipkow's approach to this problem, when they
verified $\mathcal{W}$ in Isabelle, was to thread an infinite source of known globally unique variable names (i.e.\ a natural number $n$ for which all
names in $\{ N_i | i \ge n\}$ are unique and unused) as state through the program, removing a name from the source when a fresh variable was
introduced (i.e.\ incrementing $n$) \cite{Naraschewski:1999:TIV:594135.594270}. While this approach is perhaps closer to how $\mathcal{W}$ would be
implemented in a compiler, it has a certain inelegance that complicates Agda definitions of these rules considerably. Specifically, the rules would
need to live within a state monad, introducing needless dependency between rule invocations which would otherwise be independent.

Our approach is instead to reuse some machinery that is already present in $\outsidein$ for local assumptions. We shall extend the constraint language
slightly while generating constraints, and simplify it again before solving them. Specifically, we add another form to the extended constraint
language $C$: an (existential) quantifier for unification variables, which we denote with $\Finv \alpha.\ C$ ($\Finv$ is used here rather than
$\exists$ to distinguish between the two existential quantifiers in $C$; $\exists$ is for local assumptions, and $\Finv$ is for unification
variables). This approach is similar to the existential quantifiers used in \cite{Pottier:2005ue}.

To use these quantifiers, we must first rearrange the constraint generation rules so that the type is viewed as \emph{input}, rather than output. This
does not affect the algorithm significantly --- types are always just a single metavariable\footnote{This does not lead to ambiguity dangers, as the
   system is still syntax-directed}, and the exact form of the inferred type is instead indicated by an explicit equality constraint. This means that
the only place where these new unification variables are mentioned is within the generated constraint, and not within the type:

\nopagebreak

\begin{displaymath}
\inferrule{\alpha\ \textbf{fresh} \\ \beta\ \textbf{fresh} \\ \Gamma,(x : \alpha) \vdasharrow e : \beta \leadsto C }
          {\Gamma \vdasharrow \lambda x.\ e : \tau \leadsto C \land (\tau \sim (\alpha \rightarrow \beta))}
\end{displaymath}

\medskip

Then, we can simply add an environment of available type variables $\Delta$ to the constraint generation judgement, and replace the fresh
variable introductions with quantifiers (where $\alpha$ and $\beta$ are not in the environment $\Delta$):

\begin{displaymath}
\inferrule{\alpha, \beta, \Delta; \Gamma,(x : \alpha) \vdasharrow e : \beta \leadsto C }
          {\Delta; \Gamma \vdasharrow \lambda x.\ e : \tau \leadsto \Finv \alpha.\ \Finv \beta.\ C \land (\tau \sim (\alpha \rightarrow \beta))}
\end{displaymath}

\medskip
\begin{figure}
\caption{Constraint Generation Rules (using our new quantifier)}
\label{fig:constraintgen}
\renewcommand{\arraystretch}{3}
\begin{displaymath}
	\begin{array}{c}
		\text{\framebox{$\Delta;\Gamma \vdasharrow e : \tau \leadsto C$}} \\
		\inferrule*[Right=VarCon]
        {(v : \forall\bar{a}.\ Q_1 \Rightarrow \tau_1) \in \Gamma}
        {\Delta;\Gamma \vdasharrow v : \tau \leadsto 
            \Finv \bar{\alpha}.\ [\overline{a \mapsto \alpha}]Q_1 \land' (\tau \sim [\overline{a \mapsto \alpha}]\tau_1) } \\
		\inferrule*[Right=App]
        {\alpha_1,\alpha_2,\alpha_3,\Delta;\Gamma \vdasharrow e_1 : \alpha_1 \leadsto C_1 
          \\ \alpha_1,\alpha_2,\alpha_3,\Delta;\Gamma \vdasharrow e_2 : \alpha_2 \leadsto C_2}
        {\Delta;\Gamma \vdasharrow e_1\ e_2 : \tau \leadsto 
          \Finv \alpha_1.\ \Finv \alpha_2.\ \Finv \alpha_3.\ C_1 \land' C_2 
            \land' (\alpha_1 \sim (\alpha_2 \rightarrow \alpha_3)) \land' (\tau \sim \alpha_3)  } \\
		\inferrule*[Right=Abs]
        {\alpha,\beta,\Delta;\Gamma,(x : \alpha) \vdasharrow e : \beta \leadsto C }
        { \Delta;\Gamma \vdasharrow \lambda x.\ e : \tau \leadsto \Finv \alpha.\ \Finv \beta.\ C \land' (\tau \sim (\alpha \rightarrow \beta))} \\
		\inferrule*[Right=Let]
        {\alpha_1,\alpha_2,\Delta;\Gamma \vdasharrow e_1 : \alpha_1 \leadsto C_1 
          \\ \alpha_1,\alpha_2,\Delta;\Gamma,(x : \alpha_1) \vdasharrow e_2 : \alpha_2 \leadsto C_2}
        {\Delta; \Gamma \vdasharrow \mathtt{let}\ x = e_1\ \mathtt{in}\ e_2 : \tau 
           \leadsto \Finv \alpha_1.\ \Finv \alpha_2.\ C_1 \land' C_2 \land' (\tau \sim \alpha_2) } \\
	   \inferrule*[Right=LetA]
        {\alpha_1,\alpha_2,\Delta;\Gamma \vdasharrow e_1 : \alpha_1 \leadsto C_1 
          \\ \alpha_1,\alpha_2,\Delta; \Gamma,(x : \alpha_1) \vdasharrow e_2 : \alpha_2 \leadsto C_2}
        {\Delta;\Gamma \vdasharrow \mathtt{let}\ x\ \mathtt{::}\ \tau' = e_1\ \mathtt{in}\ e_2 : \tau \leadsto
           \Finv \alpha_1.\ \Finv \alpha_2.\ C_1 \land' C_2 \land' (\tau \sim \alpha_2) \land' (\alpha_1 \sim \tau')} \\
	\inferrule*[Right=GLetA]
     {\sigma_1 = \forall\bar{a}.\ Q \Rightarrow \tau' \\ 
	   Q \neq \epsilon\ \text{or}\ \bar{a} \neq \epsilon \\
	   \bar{\alpha},\beta_1,\beta_2, \Delta; \Gamma \vdasharrow e_1 : \beta_1 \leadsto C \\\\			   
	   C_1 = \Finv \bar{\alpha}.\ \exists \epsilon.\ ([\overline{a \mapsto \alpha}]Q \supset C \land' \beta_1 \sim [\overline{a \mapsto \alpha}]\tau')\\
      \beta_1,\beta_2,\Delta;\Gamma,(x:\sigma_1)\vdasharrow e_2 : \beta_2 \leadsto C_2
	  }
     {\Delta;\Gamma \vdasharrow \mathtt{let}\ x\ \mathtt{::}\ \sigma_1 = e_1\ \mathtt{in}\ e_2 : \tau 
        \leadsto \Finv \beta_1.\ \Finv \beta_2.\ C_1 \land' C_2 \land' (\tau \sim \beta_2)}			  			 \\ 
	\inferrule*[Right=Case]
     {\alpha,\beta,\bar{\gamma},\bar{\delta},\Delta;\Gamma \vdasharrow e : \alpha \leadsto C \\\\
	   (K_i : \forall \bar{a}\bar{b}.\ Q_i \Rightarrow \bar{\tau}_i \rightarrow  \mathtt{T}\ \bar{a}) \in \Gamma \\
       \alpha,\beta,\bar{\gamma},\bar{\delta},\bar{\rho},\Delta; \Gamma, (\overline{x_i : [b \mapsto \rho][a \mapsto \gamma]\tau_i})
          \vdasharrow e_i : \delta_i \leadsto C_i \\\\
		C'_i = {\begin{cases}
					 C_i \land' \delta_i \sim \beta & \text{if $\bar{b}_i = \epsilon$ and $Q_i = \epsilon$} \\
					 \Finv \bar{\rho}.\  \exists \epsilon. ([\overline{b \mapsto \rho}][\overline{a \mapsto \gamma}]Q_i) 
                   \supset C_i \land' \delta_i \sim \beta& \text{otherwise} \\
				  \end{cases}}							
	  }
     {\Delta;\Gamma \vdasharrow \mathtt{case}\ e\ \mathtt{of}\ \{\overline{K_i\ \bar{x}_i \rightarrow e_i}\} : \tau 
         \leadsto \Finv \alpha. \Finv \beta. \Finv \bar{\gamma}.\Finv \bar{\delta}.\ C \land' (\mathtt{T}\ \bar{\gamma} \sim \alpha)
           \land' (\bigwedge C'_i) \land' (\tau \sim \beta)}\\	
			  \end{array}
\end{displaymath}
\end{figure}

The changes required to most of the other rules are in a similar vein (See fig.~\ref{fig:constraintgen} for a full set). This more rigorous
formulation of constraint generation is equivalent to the original presentation, with the added benefit of a formalized notion of fresh
variables, and less ambiguity in the presentation of the constraint languages.

\subsection{The Prenexer}

Of particular interest is the interaction between local assumption forms and these fresh variable quantifiers. Here is a rule from the original
$\outsidein$ formulation where a user has specified a general type for a local {\tt let} binding:

\nopagebreak

\begin{displaymath}
	\inferrule*[Right=Original]{\sigma_1 = \forall\bar{a}.\ Q_1 \Rightarrow \tau_1 \\ 
	           Q_1 \neq \epsilon\ \text{or}\ \bar{a} \neq \epsilon \\
			   \Gamma \vdasharrow e_1 : \tau \leadsto C \\
			   \bar{\beta} = \mathit{fuv}(\tau,C) - \mathit{fuv}(\Gamma) \\\\
			   C_1 = \exists \bar{\beta}.\ (Q_1 \supset C \land \tau \sim \tau_1) \\
			   \Gamma,(x:\sigma_1)\vdasharrow e_2 : \tau_2 \leadsto C_2
			  }{\Gamma \vdasharrow \mathtt{let}\ x\ \mathtt{::}\ \sigma_1 = e_1\ \mathtt{in}\ e_2 : \tau_2 \leadsto C_1 \land C_2}
\end{displaymath}

\medskip

This rule introduces a local assumption constraint where the variables bound by the quantifier ($\exists\bar{\beta}$) are all free
unification variables introduced when generating the constraint for $e_1$ and $\tau$. With our new quantifiers, there will never be any free
unification variables under any circumstances (as any unification variables introduced would have been bound within the constraint $C$), which makes
the updated rule look somewhat odd --- the existential quantifier in the local assumption form is empty\footnote{We also have to introduce fresh
   unification variables for all those bound in the user's general type ($\bar{a}$). As they are bound \emph{outside} the implication constraint, they
   are treated as skolem variables within it. Therefore, this change does not affect the semantics of the original rule.}:

\begin{displaymath}
	\inferrule*[Right=GLetA]
     {\sigma_1 = \forall\bar{a}.\ Q \Rightarrow \tau' \\ 
	   Q \neq \epsilon\ \text{or}\ \bar{a} \neq \epsilon \\
	   \bar{\alpha},\beta_1,\beta_2, \Delta; \Gamma \vdasharrow e_1 : \beta_1 \leadsto C \\\\			   
	   C_1 = \Finv \bar{\alpha}.\ \exists \epsilon.\ ([\overline{a \mapsto \alpha}]Q \supset C \land \beta_1 \sim [\overline{a \mapsto \alpha}]\tau')\\
      \beta_1,\beta_2,\Delta;\Gamma,(x:\sigma_1)\vdasharrow e_2 : \beta_2 \leadsto C_2
	  }
     {\Delta;\Gamma \vdasharrow \mathtt{let}\ x\ \mathtt{::}\ \sigma_1 = e_1\ \mathtt{in}\ e_2 : \tau 
        \leadsto \Finv \beta_1.\ \Finv \beta_2.\ C_1 \land C_2 \land (\tau \sim \beta_2)}			  			  
\end{displaymath}

\medskip

We resolve this oddity by introducing a new constraint simplification phase, which is run before solving, called the \emph{prenexer}. The prenexer is
responsible for eliminating all of the new $\Finv$-quantifiers introduced by constraint generation, so that solving can proceed unchanged from the
original $\outsidein$ formulation. This phase is called the \emph{prenexer} because it moves the $\Finv$-quantifiers leftward, towards the front of
the constraint expression --- a logical formula is considered to be in \emph{prenex normal form} if all quantifiers are moved to the leftmost, outermost
position possible.

Despite the name, the prenexer does not necessarily leave constraints in such a normal form due to the presence of other quantifiers in the formula,
specifically the existential quantifiers introduced by local assumption constraints.   Observe the rule $\textsc{Prenex$_3$}$, where a new type
variable is bound within an implication constraint. Here, the variable bound by the $\Finv \alpha$ quantifier is added to the set of
variables bound by the existential quantifier $\exists \bar{\beta}$. This rule therefore ensures that local assumption forms again bind all
unification variables introduced within the implication, as they do in the original $\outsidein$ formulation. 

\begin{figure}
   \label{fig:prenexer}
\begin{displaymath}
	\text{\framebox{$C \stackrel{\text{pnx}_1}{\mapsto} C$}}
\end{displaymath}
\begin{displaymath}
	\begin{array}{lcrr}
		x \land' (\Finv \alpha.\ y) & \stackrel{\text{pnx}_1}{\mapsto} & \Finv \alpha.\ x \land' y & \textsc{Prenex$_1$}\\
		(\Finv \alpha.\ x) \land' y & \stackrel{\text{pnx}_1}{\mapsto} & \Finv \alpha.\ x \land' y & \textsc{Prenex$_2$}\\	
		\exists \bar{\beta}.\ Q \supset (\Finv \alpha.\ x) & \stackrel{\text{pnx}_1}{\mapsto} & \exists \bar{\beta}\alpha.\ Q \supset x &
      \textsc{Prenex$_3$} 	
	\end{array}
\end{displaymath}
\begin{displaymath}
	\text{\framebox{$C \stackrel{\text{pnx}*}{\mapsto} C$}}
\end{displaymath}
\begin{displaymath}
   \inferrule*[Right=Refl*]
     {\quad}{C \stackrel{\text{pnx}*}{\mapsto} C}\qquad\qquad\quad\inferrule*[Right=Trans*]{C_1 \stackrel{\text{pnx}_1}{\mapsto} C_2 \\ C_2
        \stackrel{\text{pnx}*}{\mapsto} C_3}{C_1 \stackrel{\text{pnx}*}{\mapsto} C_3}
   \end{displaymath}

   \medskip

	We say $C \stackrel{\text{pnx}}{\mapsto} C'$ iff $C \stackrel{\text{pnx}*}{\mapsto} C'$ and there exists no $C''$ such that $C'
   \stackrel{\text{pnx}_1}{\mapsto} C''$


\caption{Prenexer rewrite rules, and their reflexive transitive closure}
\end{figure}
\medskip

Ordinarily with a explicitly named representation of type variables, we would have to take care when performing these rewrites that no name conflicts
occur. As our representation is based on de Bruijn indices, this is quite mechanical. As each quantifier is moved out, we adjust the indices within
each expression accordingly, thus ensuring that names remain unique (See chapter~\ref{sec:terms} for details). 

Once all $\Finv$ quantifiers have been moved by the prenexer, we will have an expression of the form $\Finv \bar{\alpha}.\ C$ where $C$ consists only
of the extended syntax used originally in $\outsidein$, and all fresh names introduced by the constraint generation have been made globally unique ---
exactly the semantics of the informal \textbf{fresh} constructor used previously.  Therefore, after rewriting, we can simply pass $C$ to the
subsequent solver phase, using $\bar{\alpha}$ as the set of variables the solver may unify (see the top level rules in fig.~\ref{fig:toplevel}). 

\subsection{Solver and Separator}

\begin{figure}
      \caption{Solver, separated constraints and separator functions.}
   \begin{tabular}{llll}
   implication constraints & $I$ & $::=$ & $ \epsilon\ |\ \exists^I \bar{\alpha}.\ Q \supset \mathcal{C}\ |\ I \land^I I $ \\
   separated constraints & $\mathcal{C}$ & $::=$ & $ Q \cdot I $
   \end{tabular}

   \begin{displaymath}
      \begin{array}{lll}
         \textbf{implic}[C_1 \land' C_2 ] & = &  \textbf{implic}[C_1] \land^I \textbf{implic}[C_2] \\
         \textbf{implic}[Q] & = &  \epsilon \\
         \textbf{implic}[\exists\bar{\beta}.\  Q \supset C] &=& \exists^I\bar{\beta}.\ Q \supset \textbf{sep}[C]  \\\\
         \textbf{simple}[C_1 \land' C_2 ] & = & \textbf{simple}[C_1] \land \textbf{simple}[C_2] \\
         \textbf{simple}[Q] & = & Q \\
         \textbf{simple}[\exists\bar{\beta}.\ Q \supset C] &=& \epsilon \\
         \\
         \textbf{sep}[C] &=& \textbf{simple}[C] \cdot \textbf{implic}[C]
      \end{array} 
   \end{displaymath}
   \begin{displaymath}
		\text{\framebox{$ \mathcal{Q};Q_{\text{given}}; \overline{\alpha_\text{tch}} \stackrel{\text{solv}}{\vdasharrow} 
               \mathcal{C}_{\text{wanted}} \leadsto Q_{\text{residual}};\theta  $}}
   \end{displaymath}
   \begin{displaymath}
      \inferrule{\mathcal{Q} ; Q_g ; \bar{\alpha} \stackrel{\text{simp}}{\vdasharrow} Q \leadsto Q_r; \theta \\
                 \forall( (\exists^I \bar{\beta}_i.\ Q_i \supset \mathcal{C}_i) \in I  ).\ \mathcal{Q};Q_g \land Q_r \land Q_i ; \bar{\beta}_i
              \stackrel{\text{solv}}{\vdasharrow} \mathcal{C}_i \leadsto \epsilon; \theta_i}
                {\mathcal{Q} ; Q_g ; \bar{\alpha} \stackrel{\text{solv}}{\vdasharrow} Q \cdot I \leadsto Q_r; \theta }
   \end{displaymath}
   \label{fig:solver}
\end{figure}

Our presentation of the solver infrastructure is somewhat different to the solver infrastructure in the original paper.  Here we introduce a new form
of \emph{separated} $C$-constraint, denoted $\mathcal{C}$, which contains a vanilla $Q$-constraint, already solvable by the provided simplifier, and
a special $I$ constraint, which contains only local assumption implications (whose bodies are, in turn, separated $\mathcal{C}$ constraints, see
fig.~\ref{fig:solver}). Our solver operates on these separated constraints rather than the $C$-constraints directly, so we introduce a function
$\textbf{sep} : C \rightarrow \mathcal{C}$, defined in terms of helper functions $\textbf{simple} : C \rightarrow Q$ and $\textbf{implic} : C
\rightarrow I$, which forms an additional phase in the inference algorithm.  

In the original presentation of the $\outsidein$ solver, the separation of constraints into simple and implication components was performed inline
with the main solver rule, rather than in a separate phase. This makes the termination argument for the main solving rule slightly less clear, as it
must be established that, for all $C$, $\textbf{simple}[C]$ and $\textbf{implic}[C]$ are no larger than $C$ itself. This, while obvious to a human
observer, is not so obvious to a proof assistant. We simply sidestep any termination troubles by encoding the separation of constraints as a separate
phase, rather than interleaving them as in the original presentation.

Our main solving judgement is of the form $\mathcal{Q};Q_{\text{given}}; \overline{\alpha_\text{tch}} \stackrel{\text{solv}}{\vdasharrow}
\mathcal{C}_{\text{wanted}} \leadsto Q_{\text{residual}};\theta$, which can be read as, ``Given the axiom scheme $\mathcal{Q}$ and constraint
$Q_\text{given}$, the constraint $\mathcal{C}_{\text{wanted}}$ is simplified to $Q_{\text{residual}}$ producing the substitution $\theta$ where
$\mathit{dom}(\theta) \subseteq \overline{\alpha_\text{tch}}$.'' Note that while the solver is not obliged to solve \emph{all} constraints, the
remaining residual constraint is a \emph{Q}-constraint, not a $\mathcal{C}$-constraint, which means that, at the very least, all implication
constraints must be resolved. This is important, as the constraints left residual from the solver are abstracted over when generalising on top-level
definitions (see fig.~\ref{fig:toplevel}), and $C$ constraints do not form part of the constraint language available to the user of the language ---
It would be highly unusual for a type inference algorithm to provide type signatures that the user of the language could not express themselves! 

\begin{figure}
   \caption{Top level algorithmic rules.}
   \begin{displaymath}
		\text{\framebox{$\mathcal{Q};\Delta;\Gamma\vdasharrow \mathit{prog}$}}  
   \end{displaymath}
   \begin{displaymath}
      \inferrule*[Right=Empty]{\quad}{\mathcal{Q};\Delta;\Gamma\vdasharrow\epsilon} \qquad \qquad \qquad
      \inferrule*[Right=BindA]{\bar{a},\Delta;\Gamma \vdasharrow e : \tau \leadsto C \\
                               C \stackrel{\text{pnx}}{\mapsto} \Finv \bar{\beta}.\ C' \\
                               \mathcal{Q};Q;\bar{\beta} \stackrel{\text{solv}}{\vdasharrow} \textbf{sep}[C'] \leadsto \epsilon;\theta \\\\
                               \mathcal{Q};\Delta;\Gamma,(f : \forall \bar{a}.\ Q \Rightarrow \tau) \vdasharrow \mathit{prog} }
                              {\mathcal{Q};\Delta;\Gamma\vdasharrow f :: (\forall \bar{a}.\ Q \Rightarrow \tau) = e, \mathit{prog}}
      \end{displaymath}
      \begin{displaymath} 
      \inferrule*[Right=Bind]{\gamma, \Delta; \Gamma \vdasharrow e : \gamma \leadsto C \\
                               C \stackrel{\text{pnx}}{\mapsto} \Finv \bar{\beta}.\ C' \\
                               \mathcal{Q}; Q; \gamma, \bar{\beta} \stackrel{\text{solv}}{\vdasharrow} \textbf{sep}[C'] \leadsto Q_r;\theta \\\\
                               \bar{\alpha} = \text{free unification variables in } Q_r, \theta\gamma  \\
                               \mathcal{Q};\Delta;\Gamma,( f : \forall \bar{\alpha}.\ Q_r \Rightarrow \theta \gamma) \vdasharrow \mathit{prog}}
                              {\mathcal{Q} ; \Delta; \Gamma \vdasharrow f = e, \mathit{prog}}
      \end{displaymath}
   \label{fig:toplevel}
\end{figure}
\subsection{Top Level Rules}

Our presentation of the top-level rules differ significantly from the original $\outsidein$ presentation, in order to accommodate the other changes we
have made to the system. In particular:

\begin{itemize}

      \item As we view the type in the constraint generation rule as \emph{input} rather than \emph{output}, we do not need to add an equality
         constraint in the rule $\textsc{BindA}$, reconciling the provided type signature with the generated type. Instead, we simply pass the
         provided type directly in to constraint generation. Similarly, we cannot simply use the type returned by constraint generation in the rule
         $\textsc{Bind}$, but must instead introduce a new ``fresh'' type variable $\gamma$, use it for constraint generation, then apply the solution
         substitution $\theta$ to it in order to determine the type of $f$.

      \item As we now have an explicit notion of available type variables in the environment $\Delta$ for constraint generation, we add a similar
         environment here.

      \item Constraints must be prenexed \emph{and} separated before being solved, which necessitates some additions to the \textsc{Bind} rules.

\end{itemize}

Despite the added rigor in our version of the $\outsidein$ system, some informality still remains in these definitions - in particular, the
possibility of name conflicts is ignored, assertions are made informally about substitution domains, and the rule \textsc{Bind} in
figure~\ref{fig:toplevel} relies on an informally specified ``free unification variables'' operation. Naturally, in order to formalise this system in
a proof assistant, we still must resolve these issues. All of these problematic elements are eliminated via our representation of terms and names,
discussed in the next chapter.

\newpage


\section{Encoding Types and Terms}
\label{sec:terms}

Constraints and expressions cannot be expressed in Agda simply as a series of datatypes, because the exact structures of these terms is dependent on
the parameter $X$. $C$-constraints, which are not part of $X$, can contain $Q$-constraints, which are part of it. Similarly, expressions, not part of
$X$, can contain types, which are.

\noindent We use Agda's module system to represent this parameterisation, providing a record type \textsc{X} containing all definitions within the
parameter as an argument to our modules. Here is a sketch of the Agda code used to represent such a parameterisation:


\begin{displaymath}
   \begin{array}{l}
   \textbf{record}\ \textsc{X} : \text{Set}_1\ \textbf{where} \\ \qquad
   \textbf{field}\ \textsf{Type}\ :\  \cdots \\ \qquad 
   \textbf{field}\ \textsf{QConstraint}\ :\ \cdots \\ \qquad \cdots \\\\
   \textbf{module}\ \mathit{OutsideIn}\ ( x : \textsc{X})\ \textbf{where} \\ \qquad \textbf{open}\ X(x)\\ \qquad \cdots \\
   \qquad \textbf{data}\ \textsc{Constraint}\ \cdots \\ 
   \qquad \textbf{data}\ \textsc{Expression}\ \cdots \\ 
   \end{array}
\end{displaymath}

Note that the type of $X$ is $\text{Set}_1$, rather than the usual type-of-types $\text{Set}$, because the $X$ parameter sits one meta-level higher
than the definitions themselves --- The type $\text{Set}$ cannot contain $\text{Set}$ without making Agda inconsistent\footnote{The inconsistency
   arises from Russell's paradox}.

Over the course of this chapter, we will gradually refine this sketch into the concrete definitions we use in our formalisation. 


\subsection{Names}

One of the most commonly examined facets of term representation is how to represent variable names. Much literature has been published on the subject,
and a wide range of techniques exist. Perhaps the most common is that of the \emph{de Bruijn index} \cite{deBruijn:1972tm}, a simple system of
assigning numerical indices to binders instead of names. For example, the term $\lambda x.\ \lambda y.\ x\ y$ can be restated with (stack-based) de
Bruijn indices as $\lambda.\ \lambda.\ \mathtt{1}\ \mathtt{0}$. These indices are sometimes presented the other way around, where the innermost binder
is referenced by the \emph{highest} available index, but for our purposes, this orientation is easier. 

These indices make reasoning and manipulating terms substantially easier in many cases: avoiding name clashes when rewriting constraints is simply a
matter of small arithmetic operations on indices, and $\alpha$-equivalent terms are propositionally equal.

Nicolas Pouillard has generalised de Bruijn indices in a series of systems (implemented in Agda, no less), starting with ``Nameless, Painless'',
published in \cite{Pouillard:2011hc}. Based on the notion of an \emph{abstract world} of variable names, these systems are designed chiefly to avoid
programming errors when working with de Bruijn indices (which, over the years, have established some notoriety for being somewhat difficult beasts to
tame). While his approach is certainly not without merit, we feel that using such a library to represent terms in $\outsidein$ may needlessly
complicate our definitions. The approach we have taken, based on de Bruijn indices, allows us to exploit type-indexing techniques to generate a number
of ``theorems for free'' via parametricity \cite{Wadler:1989vy}. It is not clear that we could retain this simplicity and generality were we to rely 
on Pouillard's work.

\pagebreak

\subsection{Indexed Terms}

The simplest possible representation which uses de Bruijn indices simply uses the full set $\mathbb{N}$ to represent type variables:\footnote{Where
   $\mathbb{N}$ is the type of the standard Peano naturals with $\text{zero} : \mathbb{N}$ and $\text{suc} : \mathbb{N} \rightarrow \mathbb{N}$}

\begin{figure}[H]
\begin{displaymath}
   \begin{array}{l}
   \textbf{record}\ \textsc{X} : \text{Set}_1\ \textbf{where} \\ \qquad
   \begin{array}{llcl} 
   \textbf{field} & \textsf{Type} & : &  \text{Set} \\ 
                  & \textsf{Var} & : & \mathbb{N} \rightarrow \textsf{Type} \\
                  & \rightarrow' & : & \textsf{Type} \rightarrow \textsf{Type} \rightarrow \textsf{Type} \\
   \textbf{field} & \textsf{QConstraint} & : & \text{Set} \\
                  & \epsilon & : & \textsf{QConstraint} \\
                  & \land & : & \textsf{QConstraint} \rightarrow \textsf{QConstraint} \rightarrow \textsf{QConstraint} \\
                  & \sim & : & \textsf{Type} \rightarrow \textsf{Type} \rightarrow \textsf{QConstraint} \\
   \end{array}\\\\
   \textbf{module}\ \mathit{OutsideIn}\ ( x : \textsc{X})\ \textbf{where} \\ \qquad 
	\begin{array}{l}
      \textbf{open}\  X(x)\\ 
		\textbf{data}\  \textsc{Constraint} : \text{Set}\ \textbf{where} \\ \qquad
		               \begin{array}{lcl}
                   \mathit{QC} & : & \textsf{QConstraint} \rightarrow \textsc{Constraint} \\
						 \land'   & : & \textsc{Constraint} \rightarrow \textsc{Constraint} \rightarrow \textsc{Constraint} \\
						 \Finv    & : & \textsc{Constraint} \rightarrow \textsc{Constraint} \\
                   \exists\_.\_\supset\_ & : & \mathbb{N} \rightarrow \textsf{QConstraint} \rightarrow \textsc{Constraint} \rightarrow \textsc{Constraint}
					    \end{array} \\
     \end{array}
   \end{array}
\end{displaymath}
\caption{Na\"ive constraint representation}
\end{figure}

This encoding has a number of obvious problems. For example, all terms have an infinite number of free variables available, as the full type
$\mathbb{N}$ is used for variable names. This makes it impossible to determine instantly whether a term is closed or if a term contains free
variables; one must instead analyse the term to extract this information. A common technique used to solve this problem when encoding binders in
dependently typed languages is to index the type of terms by the number of available variables in the term. This technique is used often in generic
programming literature, such as \cite{Morris04exploringthe}, and was also shown by McBride to provide a convenient termination measure that can be
used to phrase first-order unification as structural recursion \cite{McBride:2003bg}. Reworking the above term definition to include such indexing, we
get:

\begin{figure}[H]
\begin{displaymath}
   \begin{array}{l}
   \textbf{record}\ \textsc{X} : \text{Set}_1\ \textbf{where} \\ \qquad
   \begin{array}{llcl} 
   \textbf{field} & \textsf{Type} & : & \mathbb{N} \rightarrow \text{Set} \\ 
                  & \textsf{Var} & : & \forall \{ n : \mathbb{N} \} \rightarrow \textsc{Fin}\ n \rightarrow \textsf{Type}\ n \\
                  & \rightarrow' & : & \forall \{ n : \mathbb{N} \} \rightarrow \textsf{Type}\ n \rightarrow \textsf{Type}\ n 
                                                                    \rightarrow \textsf{Type} \ n \\
   \textbf{field} & \textsf{QConstraint} & : & \mathbb{N} \rightarrow \text{Set} \\
                  & \epsilon & : & \forall \{ n : \mathbb{N} \} \rightarrow \textsf{QConstraint}\ n \\
                  & \land & : & \forall \{ n : \mathbb{N} \} \rightarrow \textsf{QConstraint}\ n \rightarrow \textsf{QConstraint}\ n 
                                                             \rightarrow \textsf{QConstraint}\ n \\
                  & \sim & : &\forall \{ n : \mathbb{N} \} \rightarrow  \textsf{Type}\ n \rightarrow \textsf{Type}\ n 
                                                           \rightarrow  \textsf{QConstraint}\ n\\
   \end{array}\\\\
   \textbf{module}\ \mathit{OutsideIn}\ ( x : \textsc{X})\ \textbf{where} \\ \qquad 
	\begin{array}{l}
      \textbf{open}\  X(x)\\ 
		\textbf{data}\  \textsc{Constraint}\ (n :\mathbb{N}) : \text{Set}\ \textbf{where} \\ \qquad
		               \begin{array}{lcl}
                   \mathit{QC} & : &   \textsf{QConstraint}\ n \rightarrow \textsc{Constraint}\ n \\
						 \land'   & : & \textsc{Constraint}\ n \rightarrow \textsc{Constraint}\ n 
                                                              \rightarrow \textsc{Constraint}\ n \\
						 \Finv    & : & \textsc{Constraint}\ (\text{suc}\ n) \rightarrow \textsc{Constraint}\ n \\
                   \exists\_.\_\supset\_ & : & (m : \mathbb{N}) \rightarrow \textsf{QConstraint}\ n \rightarrow \textsc{Constraint}\ (n + m)
          \rightarrow \textsc{Constraint}\ n
					    \end{array} \\
     \end{array}
   \end{array}
\end{displaymath}
\caption{\textsc{Fin}-named constraint representation}
\end{figure}

This definition provides a type-level distinction between closed terms and terms that may contain some free variables, eliminating the problems with
the earlier encoding. It enforces this by demanding that type variables be of type $\textsc{Fin}\ n$, where $n$ is the number of available variables
in the term. $\textsc{Fin}\ n$ is a type containing exactly $n$ inhabitants --- a finite set of natural numbers $[0,n)$ --- defined as follows:
\nopagebreak
\begin{displaymath}   
	\begin{array}{ll}
		\textbf{data} & \textsc{Fin} : \mathbb{N} \rightarrow \text{Set}\ \textbf{where} \\
		              & \begin{array}{lcl}
                         \mathit{zero} & : & \forall \{ n : \mathbb{N} \} \rightarrow \textsc{Fin}\ (\text{suc}\ n)\\
                         \mathit{suc}  & : & \forall \{ n : \mathbb{N} \} \rightarrow \textsc{Fin}\ n \rightarrow \textsc{Fin}\ (\text{suc}\ n)\\
			  		       \end{array}
     \end{array}
\end{displaymath}	 
With this definition, the previously infinite number of available variables is now restricted to a finite number described by the type index. For
example, the term $\Finv.\ \Finv.\ \mathit{QC}\ (\textsf{Var}\ \mathit{zero} \sim \textsf{Var}\ (\mathit{suc}\ \mathit{zero}))$  is closed and could therefore be of type 
$\textsc{Constraint}\ n$ for any $n : \mathbb{N}$ --- that is, it could appear in a context with any number of available variables (including
zero). The body of that constraint, $\mathit{QC}\ (\textsf{Var}\ \mathit{zero} \sim \textsf{Var}\ (\mathit{suc}\ \mathit{zero}))$, is by contrast typed most generally as 
$\textsc{Constraint}\ (\text{suc}\ (\text{suc}\ n))$ for any $n : \mathbb{N}$, which means that the term can only validly appear in a context with
two or more available variables. Therefore, our form for the $\Finv$ quantifier \emph{introduces} a new type variable by incrementing the index:
\begin{displaymath}
   \Finv : \textsc{Constraint}\ (\text{suc}\ n) \rightarrow \textsc{Constraint}\ n \\
\end{displaymath}
The local assumption constraint, unlike the $\Finv$ quantifier, introduces more than one variable at a time:
\begin{displaymath}
   \exists\_.\_\supset\_ : (m : \mathbb{N}) \rightarrow \textsf{QConstraint}\ n \rightarrow \textsc{Constraint}\ (n + m) \rightarrow
   \textsc{Constraint}\ n
\end{displaymath}
Note that the antecedent $\textsf{QConstraint}$ has only $n$ available variables, not $n + m$, as it is impossible for the antecent to mention any
unification variables introduced in the succedent $C$-constraint. 

\subsection{Nested Datatypes Approach}

While this indexing provides us a very nice way to handle de Bruijn indices for bound variables, we have not introduced an elegant way to handle type
constructors, such as \emph{Int} or \emph{Maybe}, which exist in the top-level environment. 

From the perspective of the constraint generation and solver infrastructure, type constructors are no different from type variables. One possible
solution, therefore, is to simply assign indices to these top level type constructors. This makes type constructors difficult to distinguish
from type variables, however, which becomes a serious problem when instantiating the $X$ parameter --- type constructors, which are treated as
\emph{rigid} and cannot be unified, must be distinguished from unification type variables, which can be substituted.

A common alternative is to introduce a separate $\mathit{Con}$ introduction form for $\textsf{Type}$, which refers to type constructors, as opposed to
the $\mathit{Var}$ form for type variables. This solution becomes unsatisfactory when we examine the solver infrastructure (see
fig.~\ref{fig:solver}). Note that, when solving each implication constraint, \emph{all} variables bound outside the implication constraint,
\emph{including} variables that are unifiable, are treated as rigid, skolem variables. This means that a variable previously treated as unifiable
could, in a different context, be treated as rigid like a constructor. Using a separate $\mathit{Con}$ form therefore does not bring any advantage ---
we still have some subset of the available type variables being treated as skolem. 

Our approach allows us to treat type constructors and type variables identically in the constraint generation and solver infrastructure of the
$\outsidein$ system itself, but we retain the ability to separate skolem variables from unification variables in the instantiation of the $X$
parameter. In addition, type constructors can be represented by \emph{any} type\footnote{Provided such a type has decidable equality.}, and therefore
do not need to be assigned indices, which makes working with the system a great deal more convenient. 

Our approach is to index terms not by the \emph{size} of the set of available type variables, but by the \emph{set itself}, as shown below:
\nopagebreak
\begin{figure}[H]
\begin{displaymath}
   \begin{array}{l}
   \textbf{record}\ \textsc{X} : \text{Set}_1\ \textbf{where} \\ \qquad
   \begin{array}{llcl} 
   \textbf{field} & \textsf{Type} & : & \text{Set} \rightarrow \text{Set} \\ 
                  & \textsf{Var} & : & \forall \{ n : \text{Set} \} \rightarrow n \rightarrow \textsf{Type}\ n \\
                  & \rightarrow' & : & \forall \{ n : \text{Set} \} \rightarrow \textsf{Type}\ n \rightarrow \textsf{Type}\ n 
                                                                    \rightarrow \textsf{Type} \ n \\
   \textbf{field} & \textsf{QConstraint} & : & \text{Set} \rightarrow \text{Set} \\
                  & \epsilon & : & \forall \{ n : \text{Set} \} \rightarrow \textsf{QConstraint}\ n \\
                  & \land & : & \forall \{ n : \text{Set} \} \rightarrow \textsf{QConstraint}\ n \rightarrow \textsf{QConstraint}\ n 
                                                             \rightarrow \textsf{QConstraint}\ n \\
                  & \sim & : &\forall \{ n : \text{Set} \} \rightarrow  \textsf{Type}\ n \rightarrow \textsf{Type}\ n 
                                                           \rightarrow  \textsf{QConstraint}\ n\\
   \end{array}\\\\
   \textbf{module}\ \mathit{OutsideIn}\ ( x : \textsc{X})\ \textbf{where} \\ \qquad 
	\begin{array}{l}
      \textbf{open}\  X(x)\\ 
		\textbf{data}\  \textsc{Constraint}\ (n :\text{Set}) : \text{Set}\ \textbf{where} \\ \qquad
		               \begin{array}{lcl}
                   \mathit{QC} & : &   \textsf{QConstraint}\ n \rightarrow \textsc{Constraint}\ n \\
						 \land'   & : & \textsc{Constraint}\ n \rightarrow \textsc{Constraint}\ n 
                                                              \rightarrow \textsc{Constraint}\ n \\
						 \Finv    & : & \textsc{Constraint}\ (\mathcal{S}\ n) \rightarrow \textsc{Constraint}\ n \\
                   \exists\_.\_\supset\_ & : & (m : \mathbb{N}) \rightarrow \textsf{QConstraint}\ n \rightarrow \textsc{Constraint}\ (n \oplus m)
          \rightarrow \textsc{Constraint}\ n
					    \end{array} \\
     \end{array}
   \end{array}
\end{displaymath}
\caption{Constraint representation with nested datatypes}
\end{figure}

The secret to this representation lies in the $\mathcal{S}$ data type, used when new type variables are made available by quantifiers. As an
additional bound variable is now available, the type $\mathcal{S}\ \tau$ must be isomorphic to $\tau + 1$\footnote{i.e. Haskell's {\tt Maybe} type.},
and is therefore implemented as follows:
\begin{displaymath}   
	\begin{array}{ll}		
		\textbf{data} & \mathcal{S}\ (\tau : \text{Set}) : \text{Set}\ \textbf{where} \\
		              & \begin{array}{lcl}
                         \mathit{zero} & : & \mathcal{S}\ \tau \\
						 \mathit{suc} & : & \tau \rightarrow \mathcal{S}\ \tau \\
					    \end{array} \\						
     \end{array}
\end{displaymath}	 
We also introduce another operation $\oplus$, for local assumptions, which is essentially repeated application of $\mathcal{S}$:
\begin{displaymath}
   \begin{array}{lll}
      \_ \oplus \_ & : & Set \rightarrow \mathbb{N} \rightarrow Set \\
      x \oplus \text{zero} & = & x \\ 
      x \oplus \text{suc}\ n & = & (\mathcal{S}\ x) \oplus n
      \end{array}
\end{displaymath}

\subsubsection{Monads}

One of the elegant things about this representation is that type terms can now form a categorical abstraction familiar to every Haskell programmer --- a
\emph{monad}. This monadic structure is not an original discovery; it has been demonstrated by others in the past, doing similar work on term
representation \cite{Bird:1999:DBN:968699.968702, Bellegarde:1994:SFM:202774.202788}.  Originally from category theory, a \emph{monad} is understood
by functional programmers to be a type constructor $m$, a function $unit : \alpha \rightarrow m\ \alpha$ and a \emph{Kleisli composition} operator
$\circ_m : (\beta \rightarrow m\ \gamma) \rightarrow (\alpha \rightarrow m\ \beta) \rightarrow (\alpha \rightarrow m\ \gamma)$, such that the
following laws hold:

\begin{tabular}{llll}
      \textbf{Left Identity}: & $unit \circ_m f $&$\stackrel{\cdot}{=}$&$ f$\\
      \textbf{Right Identity}:& $g \circ_m unit $&$\stackrel{\cdot}{=}$&$ g$\\
      \textbf{Associativity}: & $f \circ_m (g \circ_m h) $&$\stackrel{\cdot}{=}$&$ (f \circ_m g) \circ_m h$\\
\end{tabular}

A \emph{category} is comprised of a class of \emph{objects}, a class of \emph{arrows} or \emph{morphisms} between those objects, including an
identity morphism for each object,  and a morphism composition operation $\circ$ which must be an associative and respect identity
morphisms. From this definition, it is obvious that the above \emph{monad laws} are just restatements of the \emph{category laws} for a specific
category, called the \emph{Kleisli category} for the monad $m$. 

We introduce informally the notion of a category \textbf{Agda}, consisting of Agda types as objects, Agda functions as morphisms, $(\lambda x
\rightarrow x)$ as every identity morphism and function composition $\circ$ as morphism composition.\footnote{This is similar to the imaginary
   category \textbf{Hask} for Haskell, however unlike \textbf{Hask}, Agda types and functions \emph{do} actually form a category} Then, the Kleisli
category for $\textsf{Type}$ is a \emph{subcategory} of \textbf{Agda} with all the same objects, but only those functions with types of the form
$\alpha \rightarrow \textsf{Type}\ \beta$ as morphisms. Note that the type $\alpha \rightarrow \textsf{Type}\ \beta$ is that of a substitution;
Kleisli composition is substitution composition, where $\textsf{Var}$ is the identity substitution. $\textsf{Var}$ is therefore the $\mathit{unit}$
operation for our monad and the identity morphism for our Kleisli category.

By requiring in our $X$ parameter that $\textsf{Type}$ be a monad, we are able to assume that substitution is well-behaved with respect to the
structure of the type terms. 

\subsubsection{Functors}

We can simply derive the familiar $\mathit{bind}$ function from Kleisli composition and \emph{unit}:
\begin{displaymath}
   \begin{array}{ll}
	\mathit{bind} : (\alpha \rightarrow m\ \beta) \rightarrow m\ \alpha \rightarrow m\ \beta \\
   \mathit{bind}\ f\ a = (f \circ_m (\lambda x \rightarrow a))\ \text{it}
   \end{array}
\end{displaymath}
(Where ``$\text{it}$'' is a constructor for a unit type)

When applied to types, \emph{bind} is clearly application of a substitution to a term:
\begin{displaymath}
	\mathit{bind} :  (\alpha \rightarrow \textsf{Type}\ \beta) \rightarrow \textsf{Type}\ \alpha \rightarrow \textsf{Type}\ \beta
\end{displaymath}
Viewed categorically, \emph{bind} could be viewed here as a mapping from morphisms in the Kleisli category of $\textsf{Type}$ (i.e functions with
types of the form $\alpha \rightarrow \textsf{Type}\ \beta$) to morphisms in a new subcategory of $\textbf{Agda}$ in the image of $\textbf{Type}$,
which we call the $\textsf{Type}$-subcategory. This category has morphisms consisting of Agda functions, and objects consisting of types of the form
$\textsf{Type}\ \tau$ for any $\tau$. Note that the following two properties hold for $\mathit{bind}$:

\begin{tabular}{llll}
      \textbf{Identity}: & $\mathit{bind}\ \mathit{unit} $&$\stackrel{\cdot}{=}$&$ \mathit{id}$\\
      \textbf{Composition}:& $\mathit{bind}\ f \circ \mathit{bind}\ g $&$\stackrel{\cdot}{=}$&$ \mathit{bind}\ (f \circ_\textsf{Type} g)$\\
\end{tabular}

If we have a mapping $f$ from a category $A$ to a category $B$, such that identity maps to identity, and composition maps to composition, 
then $f$ is called a \emph{functor} from $A$ to $B$. As this is true of $\mathit{bind}$, we can say that $\mathit{bind}$ is a functor from the Kleisli
category of $\textsf{Type}$ to the $\textsf{Type}$-subcategory. 

We would like to be able to perform substitution on more than just $\mathsf{Type}$ terms. Specifically, it is also necessary to perform 
substitution on $\mathsf{QConstraint}$s and, ultimately, $\textsc{Constraint}$s.

To achieve this we require in the parameter $X$ \emph{another} functor, also from the Kleisli category of $\textsf{Type}$, but this time to the 
subcategory of \textbf{Agda} in the image of $\textsf{QConstraint}$ --- the $\textsf{QConstraint}$-subcategory: 
\begin{displaymath}
   \textit{Q-subst} : (\alpha \rightarrow \textsf{Type}\ \beta) \rightarrow (\textsf{QConstraint}\ \alpha \rightarrow \textsf{QConstraint}\ \beta)
\end{displaymath}
The functor laws tell us that this is, once again, a substitution operation:

\begin{tabular}{llll}
      \textbf{Identity}: & $\textit{Q-subst}\ \mathit{unit} $&$\stackrel{\cdot}{=}$&$ \mathit{id}$\\
      \textbf{Composition}:& $\textit{Q-subst}\ f \circ \textit{Q-subst}\ g $&$\stackrel{\cdot}{=}$&$ \textit{Q-subst}\ (f \circ_\textsf{Type} g)$\\
\end{tabular}

Given this functor, similar functors can be produced for $\textsc{Constraint}$ and, indeed, any type that similarly contains $\textsc{QConstraint}$s.
Some difficulty arises, however, when defining the functor for terms which introduce variables: The form $\Finv.\ C$ contains a subexpression of type
$\textsc{Constraint}\ (\mathcal{S}\ \alpha)$. Showing that $\mathcal{S}$ is a monad\footnote{The familiar \texttt{Maybe} monad, no less} produces the
requisite functors to transform our substitution $\alpha \rightarrow \textsf{Type}\ \beta$ to a substitution $\mathcal{S}\ \alpha \rightarrow
\textsf{Type}\ (\mathcal{S}\ \beta)$, as required for this case. 

The other case for the form $\exists n.\ Q \supset C$ contains a subexpression of type
$\textsc{Constraint}\ (\alpha\ \oplus\ n)$, which is a slightly more complicated beast to tame. Here, we must show not only that $\mathcal{S}$ is a monad, but that
$\mathcal{S} \circ \mathcal{S}$ is also, and $\mathcal{S} \circ \mathcal{S} \circ \mathcal{S}$, and so on. In other words, we have to show that for all
$n$, $\lambda \alpha.\ \alpha \oplus n$ is a monad.  Towards this end, we borrow the concept of a \emph{monad transformer}, i.e.\ a monad homomorphism \emph{lift} from
any monad $M$ to $M \circ \mathcal{S}$. By showing that \emph{lift} is monad homomorphism for the $\mathcal{S}$-transformer, and that the resultant type
$M \circ \mathcal{S}$ is a monad if $M$ is a monad, it can be trivially shown that any number of $\mathcal{S}$'s form a monad, and
thus that $\lambda \alpha.\ \alpha \oplus n$ is a monad as required.                                                                

\subsubsection{Renaming}

Another common operation for $\textsf{Type}$s, $\textsf{QConstraint}$s and so on is \emph{renaming}. Renaming can be implemented via functor
composition in terms of substitution:
\begin{displaymath}
   \begin{array}{l}
      \textit{$\tau$-rename} : (\alpha \rightarrow \beta) \rightarrow (\textsf{Type}\ \alpha \rightarrow \textsf{Type}\ \beta) \\
      \textit{$\tau$-rename}\ f = \mathit{bind}\ (\mathit{rename}\ f) \\ \\ 
      \textit{Q-rename} : (\alpha \rightarrow \beta) \rightarrow (\textsf{QConstraint}\ \alpha \rightarrow \textsf{QConstraint}\ \beta) \\
      \textit{Q-rename}\ f = \textit{Q-subst}\ (\mathit{rename}\ f) \\  \\ 
      \cdots
   \end{array}
\end{displaymath}
Where $\mathit{rename}$ is a functor from the base $\textbf{Agda}$ category to the Kleisli category of $\textsf{Type}$:
\begin{displaymath}
   \begin{array}{l}
      \textit{rename} : (\alpha \rightarrow \beta) \rightarrow (\alpha \rightarrow \textsf{Type}\ \beta) \\
      \textit{rename}\ f = \mathit{unit} \circ f
   \end{array}
\end{displaymath}
\nopagebreak
With these definitions, the common de Bruijn index ``up-shift'' substitution which increments every index is trivially $\mathit{rename}\
\mathit{suc}$. Up-shifting by multiple variables at a time can be done simply by $\mathit{rename}\ \mathit{unit}_n$ where $\mathit{unit}_n$ is the
$\mathit{unit}$ morphism of the monad $\lambda \alpha.\ \alpha \oplus n$. 

\subsubsection{A Note on Equality}

Propositional equality is defined simply in Agda\footnote{This definition is somewhat simplified - in particular, universe polymorphism is removed.},
as a data type that reifies definitional equality:

\begin{displaymath}
	\begin{array}{ll}
	\textbf{data} &\! \equiv \{A : \text{Set}\} : A \rightarrow A \rightarrow \text{Set}\ \textbf{where} \\
	              &\! \mathit{refl} : \forall \{x : A\} \rightarrow x \equiv x
    \end{array}
\end{displaymath}

\medskip

This allows us to introduce definitional equality constraints to the local context by pattern matching, in order to prove basic theorems like
transitivity and symmetry of equality:

\begin{displaymath}
	\begin{array}{l}
		\mathit{trans} :  \forall \{A : \text{Set}\}\{x\ y\ z : A\} \rightarrow x \equiv y \rightarrow y \equiv z \rightarrow x \equiv z \\
		\mathit{trans}\ \mathit{refl}\ \mathit{refl} = \mathit{refl} \\
		\\
		\mathit{sym} : \forall \{A : \text{Set}\}\{x\ y : A\} \rightarrow x \equiv y \rightarrow y \equiv z \\
		\mathit{sym}\ \mathit{refl} = \mathit{refl}
    \end{array}
\end{displaymath}

The monad and functor laws shown above, however, are in terms of extensional equality, not this propositional equality. Unfortunately, this equality
is not extensional --- that is, the statement that two functions $f$ and $g$ are propositionally equal, if, for all $x$, $f(x)$ is propositionally
equal to $g(x)$ is not provable in Agda. Any value $x$ can only be said to be propositionally equal to some other value $y$ if $x$ and $y$ both
normalise to the same result. If the definitions of two functions are (intensionally) different, they will not normalise to the same definition, even
if they give the same result for all inputs.

The general approach for proving lemmas which require extensionality is to prove them within Altenkirch's setoid-based\footnote{A \emph{setoid} being
   a dependent product $(\tau, \approx)$ where $\approx$ is an equivalence relation on the type $\tau$.} model
\cite{Altenkirch:1999:EEI:788021.788977}. As this becomes quite tedious in practice, we opt for the perhaps more inelegant approach of simply
postulating functional extensionality:

\begin{displaymath}
	\textbf{postulate}\ \mathit{extensionality} : \{A\ B : \text{Set}\}\{f\ g : A \rightarrow B \} 
                   \rightarrow (\forall x \rightarrow f\ x \equiv g\ x) \rightarrow f \equiv g
\end{displaymath}

\medskip

Agda's logic is consistent with this postulate, however we do lose the sometimes-valuable property of \emph{canonicity} for equality proofs -- that
is, not all equality proofs normalise to a canonical closed term (i.e \emph{refl}), as the postulate prevents normalisation. In practice, this means
that programs which depend on this postulate will not give meaningful results (they crash the program much like Haskell's {\tt error}), however the
postulate can be freely used for proof work - that is, to show that a particular type is inhabited.

We do not need extensionality to model the $\outsidein$ algorithm itself. We require it only to prove monad laws and similar identities about our term
representation. The loss of canonicity in exchange for simpler proofs is a trade we deem acceptable.

\subsection{Expressions}

Our representation of \textsc{Expression}s merits some attention as it is indexed by not one, but \emph{two} types --- one for available type variable
names, and one for available variables on the \emph{value} level:

\begin{displaymath}
         \textbf{data}\ \textsc{Expression}\ (\mathit{ev}\ \mathit{tv} : \text{Set}) :\ \cdots
\end{displaymath}

This approach brings a number of advantages. For example, type environments like $\Gamma$ can be represented as a total function --- it is impossible
for an environment lookup to fail. This also ensures that we update the type environment whenever new value-level variables are available.

It is problematic, however, when dealing with pattern matching. Inside a pattern alternative, some number of new variables are introduced into scope.
The exact number of variables, however, is dependent on the \emph{type} (or, at least, the arity) of the data constructor in the pattern. Furthermore, it
is already true that data constructors require special treatment --- only data constructor names may appear in patterns. 

This calls for a more sophisticated representation of names in expressions. Instead of simply using $\mathit{ev}$ to refer to value-level variables,
we will use $\textsc{Name}\ \mathit{ev}$, defined as follows:

\begin{displaymath}
\begin{array}{l}
         \textbf{data}\ \textsc{NameType} : \text{Set}\ \textbf{where} \\
         \quad \begin{array}{cll}
            \mathit{Binding} & : & \textsc{NameType} \\
            \mathit{Datacon} & : & \mathbb{N} \rightarrow \textsc{NameType}
         \end{array} \\ \\
         \textbf{data}\ \textsc{Name}\ (n : \text{Set})\ :\ \textsc{NameType} \rightarrow \text{Set}\ \textbf{where} \\
         \quad \begin{array}{cll}
            \mathit{N} & : & n \rightarrow \textsc{Name}\ n\ \mathit{Binding} \\
            \mathit{DC} & : & \forall\ \{ x \} \rightarrow \textsf{dc}\ x \rightarrow \textsc{Name}\ n\ (\mathit{Datacon}\ x)
         \end{array} 
         \end{array} 
\end{displaymath}

(Where \textsf{dc} is a type for datacon names, indexed by their arity, provided in the parameter $X$)


A \textsc{Name} can signify, therefore, either a straightforward binding \emph{or} a data constructor of some arity. As this information is presented
in the type $\textsc{Name}$, we can easily produce the desired type for a pattern matching alternative:
\begin{displaymath}
   \begin{array}{l}
         \textbf{data}\ \textsc{Alternative}\ (\mathit{ev}\ \mathit{tv} : \text{Set}) : \textsc{Shape} \rightarrow \text{Set}\ \textbf{where} \\
         \quad \begin{array}{lll}
            \stackrel{\text{alt}}{\longrightarrow} & : & \forall \{ n : \mathbb{N} \} \rightarrow \textsc{Name}\ \mathit{ev}\ (\mathit{Datacon}\ n)
      \rightarrow \textsc{Expression}\ (\mathit{ev}\ \oplus\ n)\ \mathit{tv}\ \rightarrow \\ & & \textsc{Alternative}\ \mathit{ev}\ \mathit{tv}
         \end{array}
         \end{array}
\end{displaymath}

This technique works greatly to our advantage, as there is another instance where data constructors require special treatment, this time in constraint
generation. Observe the two rules in constraint generation where the environment is consulted; the rules $\textsc{App}$ and $\textsc{Case}$:
\begin{displaymath}
   \begin{array}{l}
		\inferrule*[Right=App]
        {\alpha_1,\alpha_2,\alpha_3,\Delta;\Gamma \vdasharrow e_1 : \alpha_1 \leadsto C_1 
          \\ \alpha_1,\alpha_2,\alpha_3,\Delta;\Gamma \vdasharrow e_2 : \alpha_2 \leadsto C_2}
        {\Delta;\Gamma \vdasharrow e_1\ e_2 : \tau \leadsto 
          \Finv \alpha_1.\ \Finv \alpha_2.\ \Finv \alpha_3.\ C_1 \land' C_2 
            \land' (\alpha_1 \sim (\alpha_2 \rightarrow \alpha_3)) \land' (\tau \sim \alpha_3)  } \\     \\
	\inferrule*[Right=Case]
     {\alpha,\beta,\bar{\gamma},\bar{\delta},\Delta;\Gamma \vdasharrow e : \alpha \leadsto C \\\\
	   (K_i : \forall \bar{a}\bar{b}.\ Q_i \Rightarrow \bar{\tau}_i \rightarrow  \mathtt{T}\ \bar{a}) \in \Gamma \\
       \alpha,\beta,\bar{\gamma},\bar{\delta},\bar{\rho},\Delta; \Gamma, (\overline{x_i : [b \mapsto \rho][a \mapsto \gamma]\tau_i})
          \vdasharrow e_i : \delta_i \leadsto C_i \\\\
		C'_i = {\begin{cases}
					 C_i \land' \delta_i \sim \beta & \text{if $\bar{b}_i = \epsilon$ and $Q_i = \epsilon$} \\
					 \Finv \bar{\rho}.\  \exists \epsilon. ([\overline{b \mapsto \rho}][\overline{a \mapsto \gamma}]Q_i) 
                   \supset C_i \land' \delta_i \sim \beta& \text{otherwise} \\
				  \end{cases}}							
	  }
     {\Delta;\Gamma \vdasharrow \mathtt{case}\ e\ \mathtt{of}\ \{\overline{K_i\ \bar{x}_i \rightarrow e_i}\} : \tau 
         \leadsto \Finv \alpha. \Finv \beta. \Finv \bar{\gamma}.\Finv \bar{\delta}.\ C \land' (\mathtt{T}\ \bar{\gamma} \sim \alpha)
           \land' (\bigwedge C'_i) \land' (\tau \sim \beta)}\\	
        \end{array}
\end{displaymath}

Note that in each instance, the form of the type schema retrieved from the environment is different! One form for  data constructors, and another
for bindings. As $\textsf{Type}$ is part of the $X$ parameter, we do not have the luxury of simply pattern-matching on the structure of the type
schema to determine if it is of the correct form. Instead we adjust our encoding of type schema, in order to force the user to provide
correctly-structured types in the environment for data constructors. Specifically, we index our representation of type schema by a \textsc{NameType},
providing a general type schema form for types of regular \textit{Binding}s but more structured forms for data constructors:

\begin{displaymath}
   \begin{array}{l}
   \textbf{data}\ \textsc{TypeSchema}\ (\mathit{tv} : \text{Set}) : \textsc{NameType} \rightarrow \text{Set}\ \textbf{where} \\
   \quad\begin{array}{cll}
      \forall'\_.\_\!\Rightarrow\!\_ & : & (n : \mathbb{N}) \rightarrow \textsf{QConstraint}\ (\mathit{tv}\ \oplus\ n) \rightarrow \textsf{Type}\
      (\mathit{tv} \oplus n) \rightarrow \textsc{TypeSchema}\ \mathit{tv}\ \mathit{Regular} \\
      \forall'\_.\_\!\longrightarrow\!\_ & : & (a : \mathbb{N})\ \{r : \mathbb{N}\} \rightarrow \textsc{Vec}\ (\textsf{Type}\ (\mathit{tv}\ \oplus\ a))\ r
\rightarrow \mathit{tv} \rightarrow \textsc{TypeSchema}\ \mathit{tv}\ (\mathit{Datacon}\ r) \\
      \forall'\_,\_.\_\!\Rightarrow\!\_\!\longrightarrow\!\_ & : & (a\ b : \mathbb{N})\ \{r : \mathbb{N}\} \rightarrow \textsf{QConstraint}\ (\mathit{tv}\ \oplus\ a\ \oplus\ b) 
                 \rightarrow \\ & & \textsc{Vec}\ (\textsf{Type}\ (\mathit{tv}\ \oplus\ a\ \oplus\ b))\ r \rightarrow \mathit{tv} \rightarrow
           \textsc{TypeSchema}\ \mathit{tv}\ (\mathit{Datacon}\ r)
    \end{array}
        \end{array}
\end{displaymath}

Here, we use a length-indexed vector $\textsc{Vec}$ to ensure that the arity of the function type in a data constructor matches the arity mentioned in
its \textsc{Name}. 

This allows us to define environments as a total mapping of any $\textsc{Name}$ of type $n$ to $\textsc{TypeSchema}$ for the same name type $n$.

\begin{displaymath}
   \begin{array}{l}
   \mathit{Environment} : \text{Set} \rightarrow  \text{Set} \rightarrow \text{Set} \\
  \mathit{Environment}\ \mathit{ev}\ \mathit{tv} = \forall \{n : \textsc{NameType} \} \rightarrow \textsc{Name}\ \mathit{ev}\ n \rightarrow
  \textsc{TypeSchema}\ \mathit{tv}\ n 
        \end{array}
\end{displaymath}

\begin{figure}
   \caption{The complete \textsc{Expression} representation}
   \begin{displaymath}
      \begin{array}{l}
         \textbf{data}\ \textsc{NameType} : \text{Set}\ \textbf{where} \\
         \quad \begin{array}{cll}
            \mathit{Binding} & : & \textsc{NameType} \\
            \mathit{Datacon} & : & \mathbb{N} \rightarrow \textsc{NameType}
         \end{array} \\ \\
         \textbf{data}\ \textsc{Name}\ (n : \text{Set})\ :\ \textsc{NameType} \rightarrow \text{Set}\ \textbf{where} \\
         \quad \begin{array}{cll}
            \mathit{N} & : & n \rightarrow \textsc{Name}\ n\ \mathit{Binding} \\
            \mathit{DC} & : & \forall\ \{ x \} \rightarrow \textsf{dc}\ x \rightarrow \textsc{Name}\ n\ (\mathit{Datacon}\ x)
         \end{array} \\ \\
         \textbf{data}\ \textsc{Alternative}\ (\mathit{ev}\ \mathit{tv} : \text{Set}) : \textsc{Shape} \rightarrow \text{Set}\ \textbf{where} \\
         \quad \begin{array}{lll}
            \stackrel{\text{alt}}{\longrightarrow} & : & \forall \{ n : \mathbb{N} \}\{\sigma : \textsc{Shape}\} \rightarrow \textsc{Name}\ \mathit{ev}\ (\mathit{Datacon}\ n)
      \rightarrow \textsc{Expression}\ (\mathit{ev}\ \oplus\ n)\ \mathit{tv}\ \sigma \rightarrow \\ & & \textsc{Alternative}\ \mathit{ev}\ \mathit{tv}\
   (\mathit{Unary}\ \sigma)
         \end{array} \\ \\
         \textbf{data}\ \textsc{Alternatives}\ (\mathit{ev}\ \mathit{tv} : \text{Set}) : \textsc{Shape} \rightarrow \text{Set}\ \textbf{where} \\
         \quad \begin{array}{cll}
            \mathit{esac} & : & \textsc{Alternatives}\ \mathit{ev}\ \mathit{tv}\ \mathit{Nullary} \\
            \Vert & : &  \forall \{\sigma_1\ \sigma_2 : \textsc{Shape}\} \rightarrow \textsc{Alternative}\ \mathit{ev}\ \mathit{tv}\ \sigma_1
      \rightarrow \textsc{Alternatives}\ \mathit{ev}\ \mathit{tv}\ \sigma_2 \rightarrow \\ & &  \textsc{Alternatives}\ \mathit{ev}\ \mathit{tv}\
   (\mathit{Binary}\ \sigma_1\ \sigma_2) 
         \end{array} \\ \\
         \textbf{data}\ \textsc{Expression}\ (\mathit{ev}\ \mathit{tv} : \text{Set}) : \textsc{Shape} \rightarrow \text{Set}\ \textbf{where} \\
      \quad \begin{array}{cll}
         \mathit{EVar} & : & \forall \{x : \textsc{NameType}\} \rightarrow \textsc{Name}\ \mathit{ev}\ x \rightarrow \textsc{Expression}\ \mathit{ev}\
   \mathit{tv}\ \mathit{Nullary} \\
         \lambda' & : & \forall \{ \sigma : \textsc{Shape} \} \rightarrow \textsc{Expression}\ (\mathcal{S}\ \mathit{ev})\ \mathit{tv}\ \sigma \rightarrow
   \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ (\mathit{Unary\ \sigma}) \\
         \mathit{app} & : & \forall \{ \sigma_1\ \sigma_2 : \textsc{Shape} \} \rightarrow \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ \sigma_1
   \rightarrow \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ \sigma_2 \rightarrow  \\ & & \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ (\mathit{Binary}
\ \sigma_1\ \sigma_2) \\
         \mathit{let} & : & \forall \{ \sigma_1\ \sigma_2 : \textsc{Shape} \} \rightarrow \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ \sigma_1
   \rightarrow \textsc{Expression}\ (\mathcal{S}\ \mathit{ev})\ \mathit{tv}\ \sigma_2 \rightarrow \\ &&\textsc{Expression}\ \mathit{ev}\ \mathit{tv}\
(\mathit{Binary}\ \sigma_1\ \sigma_2) \\
         \mathit{let}_a & : & \forall \{ \sigma_1\ \sigma_2 : \textsc{Shape} \} \rightarrow \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ \sigma_1
   \rightarrow \textsf{Type}\ \mathit{tv} \rightarrow \textsc{Expression}\ (\mathcal{S}\ \mathit{ev})\ \mathit{tv}\ \sigma_2 \rightarrow \\ &&\textsc{Expression}\ \mathit{ev}\ \mathit{tv}\
(\mathit{Binary}\ \sigma_1\ \sigma_2) \\
         \mathit{let}_{ga} & : & \forall \{ \sigma_1\ \sigma_2 : \textsc{Shape} \} \rightarrow (n : \mathbb{N}) \rightarrow \textsc{Expression}\
   \mathit{ev}\ (\mathit{tv}\ \oplus\ n)\ \sigma_1 \rightarrow \\ & & \textsf{QConstraint}\ (\mathit{tv}\ \oplus\ n)
   \rightarrow \textsf{Type}\ (\mathit{tv} \oplus n) \rightarrow \textsc{Expression}\ (\mathcal{S}\ \mathit{ev})\ \mathit{tv}\ \sigma_2 \rightarrow \\ &&\textsc{Expression}\ \mathit{ev}\ \mathit{tv}\
(\mathit{Binary}\ \sigma_1\ \sigma_2) \\
         \mathit{case} & : & \forall \{ \sigma_1\ \sigma_2 \} \rightarrow \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ \sigma_1 \rightarrow
   \textsc{Alternatives}\ \mathit{ev}\ \mathit{tv}\ \sigma_2 \rightarrow \\ & &  \textsc{Expression}\ \mathit{ev}\ \mathit{tv}\ (\mathit{Binary}\ \sigma_1\
\sigma_2) 
         \end{array}
      \end{array}
%  mutual 
%      let____in_ :  {a a}  (n : )  Expression ev (tv  n) a  
%                                   QConstraint (tv  n) 
%                                   Type (tv  n) 
%                                   Expression ( ev) tv a 
%                                   Expression ev tv (Binary a a)
%      case_of_ :  {r r}  Expression ev tv r  Alternatives ev tv r 
%                Expression ev tv (Binary r r)
      
   \end{displaymath}
\end{figure}




\subsection{Shape Indexing}


\subsection{Expressions and Names}


\subsection{Environments}

\newpage
\section{Representing $\outsidein$}



\newpage
\section{Simple Instantiation}

This chapter describes a simple instantiation of the $X$ parameter of the $\outsidein$ system. We have formalised this instantiation in Agda and used
it to infer types for basic programs.

By developing this simple instantiation, we not only provide a way to actually \emph{use} the type checker we have formalised, but we also ensure that
it is in fact \emph{possible} to instantiate. Otherwise, it would be possible that the requirements in the $X$ parameter were too onerous to actually be
instantiable\footnote{As a most extreme example: if we had, by some accident, required a proof of $\bot$ in our $X$ parameter, this would not only be 
   impossible to instantiate, it would also render any proof about the system entirely useless!}.  

Our instantiation of $\textsf{QConstraint}$ is the smallest that meets the requirements of the $X$ parameter. It consists only of $\epsilon$,
constraint conjunction and type equality constraints:
\begin{displaymath}
   \begin{array}{l}
      \textbf{data}\ \textsc{QConstraint}\ (x : \text{Set}) : \text{Set}\ \textbf{where} \\
      \quad \begin{array}{lll}
      \sim\ & : & \textsc{Type}\ x \rightarrow \textsc{Type}\ x \rightarrow \textsc{QConstraint}\ x \\ 
      \land & : & \textsc{QConstraint}\ x \rightarrow \textsc{QConstraint}\ x \rightarrow \textsc{QConstraint}\ x  \\
      \epsilon\ & : & \textsc{QConstraint}\ x
      \end{array}
   \end{array}
\end{displaymath}

\textsc{Type}s consist of type variables (or constructors), type application and function types --- the typical assortment of types from System F.
\begin{displaymath}
   \begin{array}{l}
      \textbf{data}\ \textsc{Type}\ (x : \text{Set}) : \text{Set}\ \textbf{where} \\
      \quad \begin{array}{lll}
        \mathit{Var} & : &  n \rightarrow \textsc{Type}\ n \\
        \rightarrow' & : &  \textsc{Type}\ n \rightarrow \textsc{Type}\ n \rightarrow \textsc{Type}\ n \\
        \mathit{app} & : &  \textsc{Type}\ n \rightarrow \textsc{Type}\ n \rightarrow \textsc{Type}\ n \\
         \end{array}
   \end{array}
\end{displaymath}
\textsc{Type}s are also a monad, as required by the $X$ parameter, but this proof is entirely uneventful and uninteresting, as is the proof of the
functor laws for the $\textit{Q-subst}$ functor. Indeed, the only truly interesting component of the simple instantiation is the simplifier.

The simplest possible simplifier is simply the no-op:

\begin{displaymath}
   \mathcal{Q}\ ;\ Q_g\ ;\ \overline{\alpha_\text{tch}} \vdasharrow Q_w \leadsto Q_w\ ;\ \mathit{unit}_\textsf{Type}
\end{displaymath}

While this simplifier meets the simplifier soundness and principality criteria in figure~\ref{fig:entailment}, it is not a particularly interesting
simplifier to work with. Instead, we define a simplifier that is actually capable of solving constraints. 

Broadly speaking, the simplifier is divided into two main components:

\begin{enumerate}
      \item \textbf{Unification}, for solving equality constraints. 
      \item \textbf{Solving}, which uses the results from unification to solve constraint terms.
\end{enumerate}

\subsection{Unification}

Unification is the process of producing a substitution $\theta$ given two terms $\tau_1$ and $\tau_2$ such that $\theta\tau_1 \equiv \theta\tau_2$.
Unification for first-order terms is decidable via Robinson's algorithm \cite{Robinson:1965:MLB:321250.321253}, but this has a nontrivial termination
argument, based on the fact that each variable substituted reduces the number of available variables in the term. This gives a termination measure,
but it is not one that is immediately visible as a structural recursion. This is problematic in Agda, which mandates that all functions be
structurally recursive. 

McBride more recently demonstrated a structurally recursive presentation of first-order unification in a dependently typed setting, indexing terms
by the number of available unification variables \cite{McBride:2003bg}. For the purposes of our unification, we shamelessly reuse his presentation
with little modification.

One slight difference is that our $\textsc{Type}$ terms do not come indexed by the number of available variables they contain. Rather, they 
come in the form $\textsc{Type}\ (\tau\ \oplus\ n)$, with skolem variables and constructor names represented by the type $\tau$, and $n$ unification 
variables available. We define our unification algorithm in terms of a special type used for names, which explicitly separates skolem from unification
variables --- after all, they are treated very differently when performing unification:

\begin{displaymath}
   \begin{array}{l}
   \textbf{data}\ \textsc{SName}\ (\mathit{sk} : \text{Set})\ (\mathit{un} : \mathbb{N}) : \text{Set}\ \textbf{where} \\
   \quad \begin{array}{lll}
      \mathit{unification} & : & \textsc{Fin}\ \mathit{un} \rightarrow \textsc{SName}\ \mathit{sk}\ \mathit{un} \\
      \mathit{rigid}       & : & \mathit{sk} \rightarrow \textsc{SName}\ \mathit{sk}\ \mathit{un}
    \end{array}
   \end{array}
\end{displaymath}

Then, we define the straightforward isomorphism between the type used for names in the simplifier, and this special $\textsc{SName}$ type used in the
unification:

\begin{displaymath}
   \begin{array}{l}
      \mathit{iso}_1 : \forall \{m : \mathbb{N}\}\{t : \text{Set} \} \rightarrow t \oplus m \rightarrow \textsc{SName}\ t\ m \\
      \mathit{iso}_2 : \forall \{m : \mathbb{N}\}\{t : \text{Set} \} \rightarrow \textsc{SName}\ t\ m \rightarrow t \oplus m
   \end{array}
\end{displaymath}

This isomorphism can be applied to types and constraints using the standard \emph{rename} functors, which allows us to use a convenient 
representation for unification without affecting any other component of the instantiation or of the system.

As this representation trivially ensures that the domain of any substitution is restricted only to the unification variables
$\overline{\alpha_\text{tch}}$, we omit mention of $\overline{\alpha_\text{tch}}$ in figure 10.

\subsection{Solving}

\begin{figure}
   \label{fig:simpl}
   \begin{displaymath}
      \text{\fbox{$\mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} Q_w \leadsto Q_r\ ;\ \theta $}}
   \end{displaymath}
   \begin{displaymath}
      \inferrule*[Right=Empty]{\quad}
                             {\mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} \epsilon \leadsto \epsilon\ ;\ \mathit{unit}_\textsf{Type}}
   \end{displaymath}
   \begin{displaymath}
      \inferrule*[Right=Conj]{\mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} Q_1 \leadsto Q_1'\ ;\ \theta_1 \\ 
                              \mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} \theta_1 Q_2 \leadsto Q_2'\ ;\ \theta_2  }
                             {\mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} Q_1 \land Q_2 \leadsto \theta_2 Q_1' \land Q_2' \ ;\ \theta_2
                                \circ_\textsf{Type} \theta_1 }
   \end{displaymath}
   \begin{displaymath}
      \inferrule*[Right=Mgu]{\tau_1\ \text{mgu}\ \tau_2 \leadsto \theta}
                             {\mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} \tau_1 \sim \tau_2 \leadsto \epsilon\ ;\ \theta } \qquad \qquad
      \inferrule*[Right=Entail]{Q_g \stackrel{\text{?}}{\vdasharrow} \tau_1 \sim \tau_2 }
                             {\mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} \tau_1 \sim \tau_2 \leadsto \epsilon\ ;\
                                \mathit{unit}_\textsf{Type} }
   \end{displaymath}
   \begin{displaymath}
      \inferrule*[Right=GiveUp]{\quad}
                             {\mathcal{Q}\ ;\ Q_g \stackrel{\text{simp}}{\vdasharrow} \tau_1 \sim \tau_2 \leadsto \tau_1 \sim \tau_2\ ;\
                                \mathit{unit}_\textsf{Type} }
   \end{displaymath}
   
   \begin{displaymath}
      \text{\fbox{$Q_g \stackrel{?}{\vdasharrow} Q_w $}} 
   \end{displaymath}

   \begin{displaymath}
      \inferrule*[Right=Refl]{\quad }
                             {Q \stackrel{\text{?}}{\vdasharrow} Q }\qquad \qquad
      \inferrule*[Right=ConjE$_1$]{Q_1 \stackrel{\text{?}}{\vdasharrow} Q }
                             {Q_1 \land Q_2 \stackrel{\text{?}}{\vdasharrow} Q } \qquad \qquad 
      \inferrule*[Right=ConjE$_2$]{Q_2 \stackrel{\text{?}}{\vdasharrow} Q }
                             {Q_1 \land Q_2 \stackrel{\text{?}}{\vdasharrow} Q }
   \end{displaymath}

   \begin{displaymath}
      \text{\fbox{$\tau_1\ \text{mgu}\ \tau_2\ \leadsto \theta $}}
   \end{displaymath}
   \begin{center}
      (first order unification)
   \end{center}
   \caption{Simple instantiation of the simplifier}
\end{figure}


The overall simplifier has to deal with the three possible constraint forms (see fig. 10). Empty $\epsilon$ constraints resolve trivially to the identity
substitution, conjunctions resolve to a composition of the substitutions resulting from each of the two conjuncts, and type equality resolves to the
most general unifier of the two types. There are two other rules for type equality: $\textsc{Entail}$, which searches for an identical constraint to
the wanted equality  within the given context in order to trivially resolve the wanted constraint; and $\textsc{GiveUp}$, which simply gives up on solving the constraint
entirely, returning it as a residual constraint. The presence of these rules makes the system not syntax-directed, and therefore it does not directly
correspond to a deterministic algorithm. We resolve this nondeterminism by introducing an ordering on the rules: $\textsc{Mgu}$ is attempted first, then
$\textsc{Entail}$, then $\textsc{GiveUp}$. 

Another problem presents itself when one attempts to encode this simplifier in Agda. In the rule $\textsc{Conj}$, the first substitution $\theta$ is
applied to the second conjunct $Q_2$, and recursion occurs on the substituted constraint $\theta Q_2$. This recursion is \emph{non-structural} ---
the dreaded termination checker has once again reared its head.

In order to convince Agda that applying a type substitution to a constraint does not affect the shape of the constraint, we employ a similar tactic to
the technique used for representing $\textsc{Expression}$s previously. We shall define a new form of constraint, indexed by its \emph{shape}:
\begin{displaymath}
   \begin{array}{l}
      \textbf{data}\ \textsc{SConstraint}\ (x : \text{Set}) : \textsc{Shape} \rightarrow \text{Set}\ \textbf{where} \\
      \quad \begin{array}{lll}
      \sim\ & : & \textsc{Type}\ x \rightarrow \textsc{Type}\ x \rightarrow \textsc{SConstraint}\ x\ \mathit{Nullary} \\ 
      \land & : & \forall \{s_1\ s_2\} \rightarrow \textsc{SConstraint}\ x\ r_1 \rightarrow \textsc{SConstraint}\ x\ r_2 
                  \rightarrow \textsc{SConstraint}\ x\ (\mathit{Binary}\ s_1\  s_2) \\
      \epsilon\ & : & \textsc{SConstraint}\ x\ \mathit{Nullary}
      \end{array}
   \end{array}
\end{displaymath}

With this indexed data type, substitution now has the following type:

\begin{displaymath}
   \textit{SC-subst} : \forall \{ \alpha\ \beta \}\{ s \} \rightarrow (\alpha \rightarrow \textsc{Type}\ \beta) 
                     \rightarrow \mathit{SConstraint}\ \alpha\ s \rightarrow \mathit{SConstraint}\ \beta\ s
\end{displaymath}

As with \textsc{Expression}s, we can now glean from the type that the \emph{shape} of the constraint term does not change with substitution.
Therefore, structural recursion can occur on the \textsc{Shape} index of the \testsc{SConstraint} term, rather than on the term itself. As
\textsc{SConstraint} and \textsc{QConstraint} are structurally identical, it is trivial to convert between them.

\newpage
\section{Future Work}

\emph{Acknowledgements}. The author would like to thank the members of the Agda community, specifically Arseniy Alekseyev, Conor McBride, Daniel
Peebles, Andrea Vezzosi and others, all of whom were of great assistance when learning Agda and developing this formalisation.

\bigskip

\bibliographystyle{alpha}
\bibliography{../cites}	
\end{document}

